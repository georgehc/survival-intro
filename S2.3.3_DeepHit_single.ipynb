{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b45f4951-fd8b-4829-a322-a0f08c3a421d",
   "metadata": {},
   "source": [
    "# Section 2.3.3: DeepHit (Single Event) Demo\n",
    "\n",
    "Author: George H. Chen (georgechen [at symbol] cmu.edu)\n",
    "\n",
    "This demo covers how to implement DeepHit (Lee et al., 2018) specialized to working with a single critical event (as in Example 2.3.1 of the monograph) with the help of PyCox and PyTorch. This demo largely builds off the exponential time-to-event prediction model demo (`S2.2.2_Exponential.ipynb`), so please look at that first as it describes the different steps of the experimental setup in more detail.\n",
    "\n",
    "In this demo, we specifically use PyCox's `DeepHitSingle` model (which is a Python class). Here, the word \"single\" shows up since we are using DeepHit with a single critical event of interest (in general, DeepHit handles competing risks, for which there is more than just a single critical event of interest).\n",
    "\n",
    "As discussed in the monograph, DeepHit is inherently a discrete time model that requires that we specify what time grid to use, so when we set up the data to be used with PyTorch training, there's an extra step of setting up a time grid and discretizing the observed times seen in the training and validation data.\n",
    "\n",
    "*Disclaimer:* Note that PyCox actually uses various conventions that are not standard in terms of working with PyTorch (it relies heavily on another package `torchtuples` by the same author as PyCox). Our demo here intentionally tries to stick to what would be considered standard PyTorch conventions (so that as a warning up front, what we present here does *not* perfectly align with the demos that come with PyCox but will more closely resemble how PyTorch is commonly used in many other settings, including for instance how model training works in TorchSurv). The key reason why we stick to standard PyTorch conventions is so that the code makes various preprocessing and model training steps more transparent, so that if you want to modify any part of these, it should be easier to do so (for instance, if you want to introduce a specific learning rate schedule, if you want to add early stopping based on a validation set integrated Brier score, if you want to control for randomness in a particular way using your own data loaders or specific random number generators, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed45bbae-a124-4865-afa0-d04f62b24610",
   "metadata": {},
   "source": [
    "### Loading in the SUPPORT dataset (Knaus et al., 1995)\n",
    "\n",
    "As with the earlier demo, we begin by defining the training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca8b9722-9480-4771-850a-592ebe83687e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 4968\n",
      "Validation set size 1243\n",
      "Test set size 2662\n",
      "\n",
      "Features before preprocessing (14 total):\n",
      "['age', 'female', 'race', 'num.co', 'diabetes', 'dementia', 'ca', 'meanbp', 'hrt', 'resp', 'temp', 'wblc', 'sod', 'crea']\n",
      "\n",
      "Features after preprocessing (19 total):\n",
      "['age_std', 'female', 'num.co_norm', 'diabetes', 'dementia', 'ca_norm', 'meanbp_std', 'hrt_std', 'resp_std', 'temp_std', 'wblc_std', 'sod_std', 'crea_std', 'race_blank', 'race_asian', 'race_black', 'race_hispanic', 'race_other', 'race_white']\n",
      "\n",
      "Events: ['death']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_full_train_raw_np, Y_full_train_np, D_full_train_np, \\\n",
    "        X_test_raw_np, Y_test_np, D_test_np, \\\n",
    "        features_before_preprocessing, features_after_preprocessing, \\\n",
    "        events, train_test_split_prespecified, \\\n",
    "        build_preprocessor_and_preprocess, apply_preprocessor = load_dataset('support')\n",
    "\n",
    "# split the \"full training set\" into the actual training set and a validation set (using a 80/20 split)\n",
    "X_train_raw_np, X_val_raw_np, Y_train_np, Y_val_np, D_train_np, D_val_np = \\\n",
    "    train_test_split(X_full_train_raw_np, Y_full_train_np, D_full_train_np,\n",
    "                     test_size=.2, random_state=0)\n",
    "\n",
    "print(f'Training set size {X_train_raw_np.shape[0]}')\n",
    "print(f'Validation set size {X_val_raw_np.shape[0]}')\n",
    "print(f'Test set size {X_test_raw_np.shape[0]}')\n",
    "print()\n",
    "\n",
    "print(f'Features before preprocessing ({len(features_before_preprocessing)} total):')\n",
    "print(features_before_preprocessing)\n",
    "print()\n",
    "\n",
    "print(f'Features after preprocessing ({len(features_after_preprocessing)} total):')\n",
    "print(features_after_preprocessing)\n",
    "print()\n",
    "\n",
    "print('Events:', events)  # only one critical event for the standard time-to-event prediction setup\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17484e8-156a-4724-a1e2-bd7f2025db68",
   "metadata": {},
   "source": [
    "We fit and apply a preprocessor to the training set. We apply (but do not re-fit) the preprocessor to the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "835b67c9-142f-47d8-82ee-e9d885e674f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np, preprocessor = build_preprocessor_and_preprocess(X_train_raw_np)\n",
    "X_val_np = apply_preprocessor(X_val_raw_np, preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3412a160-ce89-4ac6-ad4f-1f791a3ab3c1",
   "metadata": {},
   "source": [
    "### Discretizing time\n",
    "\n",
    "We use PyCox's provided `LabTransDiscreteTime` class that helps discretize time. Note that there are many ways to discretize time (see Section 2.3.2 of the monograph). Here, we are only implementing two ways (using all unique times of death, or discretizing based on some user-specified number of quantiles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3483ac40-4542-41cf-8108-8e56a06cd68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of time steps to be used with DeepHit: 109\n",
      "Time grid: [   0.    3.    4.    5.    6.    7.    8.    9.   10.   11.   12.   13.\n",
      "   14.   15.   16.   17.   18.   19.   20.   21.   22.   23.   24.   26.\n",
      "   27.   28.   30.   31.   33.   35.   37.   39.   41.   43.   45.   48.\n",
      "   51.   54.   57.   59.   63.   66.   68.   73.   76.   82.   88.   92.\n",
      "   97.  102.  108.  115.  120.  127.  135.  143.  151.  160.  167.  178.\n",
      "  186.  198.  206.  217.  227.  236.  247.  261.  275.  292.  307.  328.\n",
      "  344.  368.  384.  399.  417.  436.  452.  475.  496.  518.  539.  564.\n",
      "  592.  624.  656.  678.  715.  757.  799.  827.  871.  923.  974. 1027.\n",
      " 1085. 1131. 1184. 1228. 1258. 1345. 1415. 1530. 1599. 1690. 1760. 1813.\n",
      " 2029.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george/Projects/survival-tutorial/pycox/preprocessing/discretization.py:37: UserWarning: cuts are not unique, continue with 109 cuts instead of 128\n",
      "  warnings.warn(f\"cuts are not unique, continue with {len(cuts)} cuts instead of {num}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pycox.preprocessing.label_transforms import LabTransDiscreteTime\n",
    "\n",
    "num_time_steps = 128  # set this to 0 to use all unique times of death\n",
    "\n",
    "if num_time_steps == 0:\n",
    "    mask = (D_train_np == 1)  # boolean mask specifying which training patients experienced death\n",
    "    label_transform = LabTransDiscreteTime(np.unique(Y_train_np[mask]))\n",
    "else:\n",
    "    # use a quantile based discretization, which could possibly end up using fewer than the\n",
    "    # number of time steps requested (if it turns out that in the dataset, there are many\n",
    "    # duplicate observed times)\n",
    "    label_transform = LabTransDiscreteTime(num_time_steps, scheme='quantiles')\n",
    "\n",
    "Y_train_discrete_np, D_train_discrete_np = label_transform.fit_transform(Y_train_np, D_train_np)\n",
    "Y_val_discrete_np, D_val_discrete_np = label_transform.transform(Y_val_np, D_val_np)\n",
    "# note: PyCox's discretization code allows for the possibility that the event indicator changes\n",
    "# (if a patient's survival time is known so that the event indicator is 1, but the survival time\n",
    "# is after the maximum discrete time grid time, then the patient's event indicator is changed to\n",
    "# being censored)\n",
    "\n",
    "time_grid_train_np = label_transform.cuts\n",
    "output_num_time_steps = len(time_grid_train_np)\n",
    "print(f'Number of time steps to be used with DeepHit: {output_num_time_steps}')\n",
    "print('Time grid:', time_grid_train_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ffe5dc-1354-4ea1-bf3c-fea418cd9b0e",
   "metadata": {},
   "source": [
    "### Preparing training and validation sets for use with PyTorch\n",
    "\n",
    "Note that at this point the observed times have been converted into discrete indices. Note that at the time of writing, the code is a bit picky about the data types used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "559dc917-0b7c-402f-ad66-fef766e9a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "X_train = torch.tensor(X_train_np, dtype=torch.float32, device=device)\n",
    "Y_train = torch.tensor(Y_train_discrete_np, dtype=torch.int64, device=device)\n",
    "D_train = torch.tensor(D_train_discrete_np, dtype=torch.int32, device=device)\n",
    "train_data = list(zip(X_train, Y_train, D_train))\n",
    "\n",
    "X_val = torch.tensor(X_val_np, dtype=torch.float32, device=device)\n",
    "Y_val = torch.tensor(Y_val_discrete_np, dtype=torch.int64, device=device)\n",
    "D_val = torch.tensor(D_val_discrete_np, dtype=torch.int32, device=device)\n",
    "val_data = list(zip(X_val, Y_val, D_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5345064a-44b9-4334-80d3-1409dbd5a9aa",
   "metadata": {},
   "source": [
    "### Setting up the DeepHit model and loss\n",
    "\n",
    "We are now ready to set up the DeepHit model using PyCox's `DeepHitSingle` class. Note that PyCox's implementation of DeepHit does *not* require that what we call `base_neural_net` outputs valid probability distributions. The reason is that under the hood, when it computes the DeepHit loss, it actually applies a softmax activation right after the base neural net (specifically, it applies equation (9) of Kvamme and Borgan (2021)).\n",
    "\n",
    "As we shall see later in the demo, the `DeepHitSingle` class provides various helper functions such as predicting survival functions for test data and interpolating these survival functions so that they use a higher time resolution than what we specified in `time_grid_train_np`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d5d800a-893c-4342-a561-ca53ceee17b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from pycox.models import DeepHitSingle\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "num_input_features = X_train.size(1)\n",
    "\n",
    "base_neural_net = nn.Sequential(nn.Linear(num_input_features, 8),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(8, output_num_time_steps)).to(device)  # no softmax needed at the end\n",
    "\n",
    "# setting alpha=1.0 means that we only use the negative log likelihood loss and not also the ranking loss\n",
    "# (we do this just as an illustrative example as it corresponds to how DeepHit is first presented in\n",
    "# Example 2.3.1 of the monograph)\n",
    "deephit_model = DeepHitSingle(base_neural_net, alpha=1.0, device=device,\n",
    "                              duration_index=time_grid_train_np)\n",
    "deephit_loss = deephit_model.loss  # we'll see how to use this loss function in the next code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c36bf4-fd91-4dd5-b997-481b1a8569e2",
   "metadata": {},
   "source": [
    "### Training the model using minibatch gradient descent\n",
    "\n",
    "Just as in the exponential time-to-event prediction model demo, we use the validation set to decide on whether to use a previous epoch's learned model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b33ace96-79ed-487a-a1f4-3dc12b33194e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train loss 3.916062831878662 - val loss 3.9150960445404053\n",
      "Epoch 2 - train loss 3.893968343734741 - val loss 3.8937888145446777\n",
      "Epoch 3 - train loss 3.8696820735931396 - val loss 3.8713314533233643\n",
      "Epoch 4 - train loss 3.8404693603515625 - val loss 3.8450794219970703\n",
      "Epoch 5 - train loss 3.8037173748016357 - val loss 3.8098793029785156\n",
      "Epoch 6 - train loss 3.7631115913391113 - val loss 3.7702183723449707\n",
      "Epoch 7 - train loss 3.720085859298706 - val loss 3.726944923400879\n",
      "Epoch 8 - train loss 3.682729959487915 - val loss 3.689936399459839\n",
      "Epoch 9 - train loss 3.652803421020508 - val loss 3.6605794429779053\n",
      "Epoch 10 - train loss 3.6299426555633545 - val loss 3.6373839378356934\n",
      "Epoch 11 - train loss 3.6132731437683105 - val loss 3.621795892715454\n",
      "Epoch 12 - train loss 3.5998377799987793 - val loss 3.609221935272217\n",
      "Epoch 13 - train loss 3.5890932083129883 - val loss 3.6000239849090576\n",
      "Epoch 14 - train loss 3.5805885791778564 - val loss 3.592714309692383\n",
      "Epoch 15 - train loss 3.5737266540527344 - val loss 3.587022542953491\n",
      "Epoch 16 - train loss 3.567810297012329 - val loss 3.582689046859741\n",
      "Epoch 17 - train loss 3.562796115875244 - val loss 3.5787248611450195\n",
      "Epoch 18 - train loss 3.5584187507629395 - val loss 3.5756990909576416\n",
      "Epoch 19 - train loss 3.5545952320098877 - val loss 3.573213577270508\n",
      "Epoch 20 - train loss 3.5512514114379883 - val loss 3.5709187984466553\n",
      "Epoch 21 - train loss 3.548133134841919 - val loss 3.5696330070495605\n",
      "Epoch 22 - train loss 3.5453379154205322 - val loss 3.5682215690612793\n",
      "Epoch 23 - train loss 3.5427958965301514 - val loss 3.567103147506714\n",
      "Epoch 24 - train loss 3.540311098098755 - val loss 3.565401792526245\n",
      "Epoch 25 - train loss 3.5379786491394043 - val loss 3.5653438568115234\n",
      "Epoch 26 - train loss 3.5357601642608643 - val loss 3.5648727416992188\n",
      "Epoch 27 - train loss 3.5337157249450684 - val loss 3.564762830734253\n",
      "Epoch 28 - train loss 3.531690835952759 - val loss 3.564075231552124\n",
      "Epoch 29 - train loss 3.5297577381134033 - val loss 3.5635478496551514\n",
      "Epoch 30 - train loss 3.527829647064209 - val loss 3.563669443130493\n",
      "Epoch 31 - train loss 3.526087760925293 - val loss 3.5639259815216064\n",
      "Epoch 32 - train loss 3.524332046508789 - val loss 3.5636038780212402\n",
      "Epoch 33 - train loss 3.5226311683654785 - val loss 3.56355881690979\n",
      "Epoch 34 - train loss 3.520975351333618 - val loss 3.563769817352295\n",
      "Epoch 35 - train loss 3.5193517208099365 - val loss 3.5640933513641357\n",
      "Epoch 36 - train loss 3.517820358276367 - val loss 3.563603162765503\n",
      "Epoch 37 - train loss 3.516340494155884 - val loss 3.5632543563842773\n",
      "Epoch 38 - train loss 3.5148465633392334 - val loss 3.5642001628875732\n",
      "Epoch 39 - train loss 3.513373851776123 - val loss 3.5638742446899414\n",
      "Epoch 40 - train loss 3.5119974613189697 - val loss 3.564588785171509\n",
      "Epoch 41 - train loss 3.5106117725372314 - val loss 3.564666986465454\n",
      "Epoch 42 - train loss 3.509291648864746 - val loss 3.564818859100342\n",
      "Epoch 43 - train loss 3.5079505443573 - val loss 3.5657594203948975\n",
      "Epoch 44 - train loss 3.506664514541626 - val loss 3.5659239292144775\n",
      "Epoch 45 - train loss 3.5054123401641846 - val loss 3.566099166870117\n",
      "Epoch 46 - train loss 3.504154682159424 - val loss 3.567037343978882\n",
      "Epoch 47 - train loss 3.5029139518737793 - val loss 3.567497968673706\n",
      "Epoch 48 - train loss 3.5017712116241455 - val loss 3.567671298980713\n",
      "Epoch 49 - train loss 3.5005130767822266 - val loss 3.5678653717041016\n",
      "Epoch 50 - train loss 3.49934458732605 - val loss 3.568674087524414\n",
      "Epoch 51 - train loss 3.49821400642395 - val loss 3.5689947605133057\n",
      "Epoch 52 - train loss 3.4970388412475586 - val loss 3.569551706314087\n",
      "Epoch 53 - train loss 3.4959030151367188 - val loss 3.5704104900360107\n",
      "Epoch 54 - train loss 3.4948058128356934 - val loss 3.5707995891571045\n",
      "Epoch 55 - train loss 3.4937620162963867 - val loss 3.5712180137634277\n",
      "Epoch 56 - train loss 3.49267315864563 - val loss 3.571030378341675\n",
      "Epoch 57 - train loss 3.4916324615478516 - val loss 3.571963310241699\n",
      "Epoch 58 - train loss 3.490675449371338 - val loss 3.57249116897583\n",
      "Epoch 59 - train loss 3.4896490573883057 - val loss 3.5732674598693848\n",
      "Epoch 60 - train loss 3.4886314868927 - val loss 3.573911666870117\n",
      "Epoch 61 - train loss 3.4876928329467773 - val loss 3.574002742767334\n",
      "Epoch 62 - train loss 3.486736297607422 - val loss 3.5750458240509033\n",
      "Epoch 63 - train loss 3.4858202934265137 - val loss 3.5750460624694824\n",
      "Epoch 64 - train loss 3.484890937805176 - val loss 3.5762455463409424\n",
      "Epoch 65 - train loss 3.4839816093444824 - val loss 3.5774662494659424\n",
      "Epoch 66 - train loss 3.483095407485962 - val loss 3.5776634216308594\n",
      "Epoch 67 - train loss 3.482243537902832 - val loss 3.5775365829467773\n",
      "Epoch 68 - train loss 3.481358528137207 - val loss 3.579087972640991\n",
      "Epoch 69 - train loss 3.480551242828369 - val loss 3.579139471054077\n",
      "Epoch 70 - train loss 3.47977614402771 - val loss 3.579620599746704\n",
      "Epoch 71 - train loss 3.479004383087158 - val loss 3.5801191329956055\n",
      "Epoch 72 - train loss 3.4781603813171387 - val loss 3.5815956592559814\n",
      "Epoch 73 - train loss 3.47737717628479 - val loss 3.58185076713562\n",
      "Epoch 74 - train loss 3.4766125679016113 - val loss 3.5818824768066406\n",
      "Epoch 75 - train loss 3.4759511947631836 - val loss 3.58219838142395\n",
      "Epoch 76 - train loss 3.4752163887023926 - val loss 3.583495855331421\n",
      "Epoch 77 - train loss 3.474491834640503 - val loss 3.5839107036590576\n",
      "Epoch 78 - train loss 3.473747730255127 - val loss 3.5848753452301025\n",
      "Epoch 79 - train loss 3.4730608463287354 - val loss 3.5856869220733643\n",
      "Epoch 80 - train loss 3.472381830215454 - val loss 3.585970640182495\n",
      "Epoch 81 - train loss 3.4717464447021484 - val loss 3.585904121398926\n",
      "Epoch 82 - train loss 3.471156358718872 - val loss 3.587843894958496\n",
      "Epoch 83 - train loss 3.4704408645629883 - val loss 3.587667942047119\n",
      "Epoch 84 - train loss 3.4698057174682617 - val loss 3.5876710414886475\n",
      "Epoch 85 - train loss 3.469182014465332 - val loss 3.58915376663208\n",
      "Epoch 86 - train loss 3.4685869216918945 - val loss 3.5889058113098145\n",
      "Epoch 87 - train loss 3.4679858684539795 - val loss 3.590604305267334\n",
      "Epoch 88 - train loss 3.4674062728881836 - val loss 3.5909159183502197\n",
      "Epoch 89 - train loss 3.466813802719116 - val loss 3.591193199157715\n",
      "Epoch 90 - train loss 3.466290235519409 - val loss 3.591862916946411\n",
      "Epoch 91 - train loss 3.465708017349243 - val loss 3.5919415950775146\n",
      "Epoch 92 - train loss 3.465196371078491 - val loss 3.5926992893218994\n",
      "Epoch 93 - train loss 3.464639663696289 - val loss 3.5932865142822266\n",
      "Epoch 94 - train loss 3.464120864868164 - val loss 3.594209671020508\n",
      "Epoch 95 - train loss 3.4636454582214355 - val loss 3.5941720008850098\n",
      "Epoch 96 - train loss 3.4630839824676514 - val loss 3.5951926708221436\n",
      "Epoch 97 - train loss 3.4626150131225586 - val loss 3.5951602458953857\n",
      "Epoch 98 - train loss 3.462080717086792 - val loss 3.5956788063049316\n",
      "Epoch 99 - train loss 3.4616353511810303 - val loss 3.5954344272613525\n",
      "Epoch 100 - train loss 3.4611947536468506 - val loss 3.5967276096343994\n",
      "Best validation loss (3.5632543563842773) achieved at epoch 37\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from torch.utils.data import DataLoader\n",
    "from pycox.models.data import pair_rank_mat\n",
    "\n",
    "# minibatch gradient descent\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle=True)  # shuffling for minibatch gradient descent\n",
    "val_loader = DataLoader(val_data, batch_size, shuffle=False)  # there is no need to shuffle the validation data\n",
    "\n",
    "optimizer = torch.optim.Adam(base_neural_net.parameters(), lr=learning_rate)\n",
    "train_epoch_losses = []\n",
    "val_epoch_losses = []\n",
    "best_val_loss = float('inf')\n",
    "best_params = None\n",
    "best_epoch_index = None\n",
    "for epoch_index in range(num_epochs):\n",
    "    base_neural_net.train()\n",
    "    for X_batch, Y_batch, D_batch in train_loader:\n",
    "        neural_net_output = base_neural_net(X_batch)\n",
    "\n",
    "        # note that the loss function requires a ranking matrix to be specified;\n",
    "        # this is specific to the ranking loss that we are actually not using in this\n",
    "        # particular demo (but we leave this here since one could modify the demo\n",
    "        # easily to also be using the ranking loss, in which case this ranking matrix\n",
    "        # will be needed)\n",
    "        rank_mat = pair_rank_mat(Y_batch.cpu().numpy(), D_batch.cpu().numpy())\n",
    "        rank_mat = torch.tensor(rank_mat, dtype=torch.int, device=device)\n",
    "\n",
    "        loss_batch = deephit_loss(neural_net_output, Y_batch, D_batch, rank_mat)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # evaluate training and validation set losses\n",
    "    # (note that in practice, instead of evaluating the negative log likelihood loss,\n",
    "    # we could instead evaluate other metrics such as time-dependent concordance index,\n",
    "    # integrated Brier score, etc)\n",
    "    base_neural_net.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = torch.tensor(0.0, dtype=torch.float, device=device)\n",
    "        num_points = 0\n",
    "        for X_batch, Y_batch, D_batch in train_loader:\n",
    "            batch_num_points = X_batch.size(0)\n",
    "            neural_net_output = base_neural_net(X_batch)\n",
    "            rank_mat = pair_rank_mat(Y_batch.cpu().numpy(), D_batch.cpu().numpy())\n",
    "            rank_mat = torch.tensor(rank_mat, dtype=torch.int, device=device)\n",
    "            train_loss += deephit_loss(neural_net_output, Y_batch, D_batch, rank_mat) * batch_num_points\n",
    "            num_points += batch_num_points\n",
    "        train_loss = float(train_loss / num_points)\n",
    "        train_epoch_losses.append(train_loss)\n",
    "        print(f'Epoch {epoch_index + 1} - train loss {train_loss}', end=' ', flush=True)\n",
    "\n",
    "        val_loss = torch.tensor(0.0, dtype=torch.float, device=device)\n",
    "        num_points = 0\n",
    "        for X_batch, Y_batch, D_batch in val_loader:\n",
    "            batch_num_points = X_batch.size(0)\n",
    "            neural_net_output = base_neural_net(X_batch)\n",
    "            rank_mat = pair_rank_mat(Y_batch.cpu().numpy(), D_batch.cpu().numpy())\n",
    "            rank_mat = torch.tensor(rank_mat, dtype=torch.int, device=device)\n",
    "            val_loss += deephit_loss(neural_net_output, Y_batch, D_batch, rank_mat) * batch_num_points\n",
    "            num_points += batch_num_points\n",
    "        val_loss = float(val_loss / num_points)\n",
    "        val_epoch_losses.append(val_loss)\n",
    "        print(f'- val loss {val_loss}', flush=True)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch_index = epoch_index\n",
    "            best_params = deepcopy(base_neural_net.state_dict())\n",
    "print(f'Best validation loss ({best_val_loss}) achieved at epoch {best_epoch_index + 1}')\n",
    "base_neural_net.load_state_dict(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d591b8f-de58-4e9c-9b6b-c7111ef86487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x706fdeb46a80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, num_epochs + 1), train_epoch_losses, label='Training')\n",
    "plt.plot(range(1, num_epochs + 1), val_epoch_losses, '--', label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49807d51-72fb-42f3-a4a5-93c59657eb0a",
   "metadata": {},
   "source": [
    "### Predicting test set survival curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd16f73-ebe8-4caf-8e8f-31a2ff773547",
   "metadata": {},
   "source": [
    "We begin by preprocessing the test data using the preprocessor built using training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe28bba0-9ab4-4940-854d-54eec8eb9065",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_np = apply_preprocessor(X_test_raw_np, preprocessor).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e438a5-a175-4362-9bce-a4e84340e9f4",
   "metadata": {},
   "source": [
    "PyCox has built-in functionality for predicting survival functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfbfc717-2254-4609-841a-626c48529dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2662, 109)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surv_test_np = deephit_model.predict_surv(X_test_np, batch_size=batch_size, to_cpu=True, numpy=True)\n",
    "surv_test_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2b8425-2f1c-4b7d-a7ab-9cbcd0dd39f1",
   "metadata": {},
   "source": [
    "Note that the time grid used is precisely the one stored in `time_grid_train_np`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e180a3a7-6f72-42f9-846a-1aed3e734696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(time_grid_train_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8cf2c2-dade-417d-9b4f-b9a83c007976",
   "metadata": {},
   "source": [
    "PyCox provides a helper function `predict_surv_df` that gets both the time grid and the predicted survival functions into a Pandas DataFrame. Note that for this DataFrame, the rows correspond to time and columns correspond to the different test points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0f42528-f388-4fb7-92c6-5c27315afff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2652</th>\n",
       "      <th>2653</th>\n",
       "      <th>2654</th>\n",
       "      <th>2655</th>\n",
       "      <th>2656</th>\n",
       "      <th>2657</th>\n",
       "      <th>2658</th>\n",
       "      <th>2659</th>\n",
       "      <th>2660</th>\n",
       "      <th>2661</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999319</td>\n",
       "      <td>0.999421</td>\n",
       "      <td>0.998916</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999029</td>\n",
       "      <td>0.999091</td>\n",
       "      <td>0.999518</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.998878</td>\n",
       "      <td>0.998989</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.998592</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999376</td>\n",
       "      <td>0.997172</td>\n",
       "      <td>0.999805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.966386</td>\n",
       "      <td>0.990079</td>\n",
       "      <td>0.989549</td>\n",
       "      <td>0.991190</td>\n",
       "      <td>0.986691</td>\n",
       "      <td>0.996840</td>\n",
       "      <td>0.990878</td>\n",
       "      <td>0.992223</td>\n",
       "      <td>0.994270</td>\n",
       "      <td>0.996848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989032</td>\n",
       "      <td>0.997803</td>\n",
       "      <td>0.991950</td>\n",
       "      <td>0.991956</td>\n",
       "      <td>0.997363</td>\n",
       "      <td>0.987516</td>\n",
       "      <td>0.996628</td>\n",
       "      <td>0.991377</td>\n",
       "      <td>0.988204</td>\n",
       "      <td>0.970640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.872919</td>\n",
       "      <td>0.954802</td>\n",
       "      <td>0.972472</td>\n",
       "      <td>0.978045</td>\n",
       "      <td>0.965564</td>\n",
       "      <td>0.967528</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.979665</td>\n",
       "      <td>0.980709</td>\n",
       "      <td>0.970878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972543</td>\n",
       "      <td>0.972053</td>\n",
       "      <td>0.978847</td>\n",
       "      <td>0.978636</td>\n",
       "      <td>0.982502</td>\n",
       "      <td>0.974065</td>\n",
       "      <td>0.962700</td>\n",
       "      <td>0.955129</td>\n",
       "      <td>0.974229</td>\n",
       "      <td>0.936413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.820099</td>\n",
       "      <td>0.919456</td>\n",
       "      <td>0.958270</td>\n",
       "      <td>0.964234</td>\n",
       "      <td>0.953248</td>\n",
       "      <td>0.923308</td>\n",
       "      <td>0.965408</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>0.963457</td>\n",
       "      <td>0.939818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960980</td>\n",
       "      <td>0.932772</td>\n",
       "      <td>0.963786</td>\n",
       "      <td>0.966515</td>\n",
       "      <td>0.963416</td>\n",
       "      <td>0.961725</td>\n",
       "      <td>0.910919</td>\n",
       "      <td>0.915803</td>\n",
       "      <td>0.960137</td>\n",
       "      <td>0.919683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.744638</td>\n",
       "      <td>0.888553</td>\n",
       "      <td>0.949304</td>\n",
       "      <td>0.954284</td>\n",
       "      <td>0.944417</td>\n",
       "      <td>0.894503</td>\n",
       "      <td>0.956138</td>\n",
       "      <td>0.958616</td>\n",
       "      <td>0.953538</td>\n",
       "      <td>0.919636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952272</td>\n",
       "      <td>0.917319</td>\n",
       "      <td>0.953391</td>\n",
       "      <td>0.958142</td>\n",
       "      <td>0.952575</td>\n",
       "      <td>0.951420</td>\n",
       "      <td>0.872813</td>\n",
       "      <td>0.884279</td>\n",
       "      <td>0.947830</td>\n",
       "      <td>0.908099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599.0</th>\n",
       "      <td>0.260584</td>\n",
       "      <td>0.100707</td>\n",
       "      <td>0.116248</td>\n",
       "      <td>0.088784</td>\n",
       "      <td>0.337562</td>\n",
       "      <td>0.502196</td>\n",
       "      <td>0.103488</td>\n",
       "      <td>0.100280</td>\n",
       "      <td>0.135626</td>\n",
       "      <td>0.665883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341956</td>\n",
       "      <td>0.260377</td>\n",
       "      <td>0.090854</td>\n",
       "      <td>0.096821</td>\n",
       "      <td>0.439469</td>\n",
       "      <td>0.079623</td>\n",
       "      <td>0.386224</td>\n",
       "      <td>0.104125</td>\n",
       "      <td>0.061292</td>\n",
       "      <td>0.154872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690.0</th>\n",
       "      <td>0.257719</td>\n",
       "      <td>0.093857</td>\n",
       "      <td>0.107055</td>\n",
       "      <td>0.079984</td>\n",
       "      <td>0.328262</td>\n",
       "      <td>0.498289</td>\n",
       "      <td>0.093525</td>\n",
       "      <td>0.091284</td>\n",
       "      <td>0.126850</td>\n",
       "      <td>0.663059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333463</td>\n",
       "      <td>0.255011</td>\n",
       "      <td>0.081370</td>\n",
       "      <td>0.087851</td>\n",
       "      <td>0.432493</td>\n",
       "      <td>0.069468</td>\n",
       "      <td>0.381994</td>\n",
       "      <td>0.098139</td>\n",
       "      <td>0.052284</td>\n",
       "      <td>0.145442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760.0</th>\n",
       "      <td>0.251844</td>\n",
       "      <td>0.082882</td>\n",
       "      <td>0.098280</td>\n",
       "      <td>0.071199</td>\n",
       "      <td>0.320292</td>\n",
       "      <td>0.495036</td>\n",
       "      <td>0.079171</td>\n",
       "      <td>0.082216</td>\n",
       "      <td>0.120120</td>\n",
       "      <td>0.661010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326241</td>\n",
       "      <td>0.246574</td>\n",
       "      <td>0.074152</td>\n",
       "      <td>0.076273</td>\n",
       "      <td>0.426117</td>\n",
       "      <td>0.061536</td>\n",
       "      <td>0.376748</td>\n",
       "      <td>0.088860</td>\n",
       "      <td>0.042003</td>\n",
       "      <td>0.137495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813.0</th>\n",
       "      <td>0.245281</td>\n",
       "      <td>0.071562</td>\n",
       "      <td>0.092644</td>\n",
       "      <td>0.064950</td>\n",
       "      <td>0.311957</td>\n",
       "      <td>0.486170</td>\n",
       "      <td>0.068015</td>\n",
       "      <td>0.075951</td>\n",
       "      <td>0.113942</td>\n",
       "      <td>0.655532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318321</td>\n",
       "      <td>0.237883</td>\n",
       "      <td>0.068123</td>\n",
       "      <td>0.068728</td>\n",
       "      <td>0.415024</td>\n",
       "      <td>0.055502</td>\n",
       "      <td>0.364445</td>\n",
       "      <td>0.079687</td>\n",
       "      <td>0.034986</td>\n",
       "      <td>0.132789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029.0</th>\n",
       "      <td>0.006550</td>\n",
       "      <td>0.010198</td>\n",
       "      <td>0.009924</td>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>0.010294</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>0.009751</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008574</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.009708</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>0.007552</td>\n",
       "      <td>0.009818</td>\n",
       "      <td>0.007157</td>\n",
       "      <td>0.009407</td>\n",
       "      <td>0.010137</td>\n",
       "      <td>0.009871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows  2662 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6     \\\n",
       "0.0     0.999981  0.999319  0.999421  0.998916  0.999944  0.999988  0.999029   \n",
       "3.0     0.966386  0.990079  0.989549  0.991190  0.986691  0.996840  0.990878   \n",
       "4.0     0.872919  0.954802  0.972472  0.978045  0.965564  0.967528  0.976661   \n",
       "5.0     0.820099  0.919456  0.958270  0.964234  0.953248  0.923308  0.965408   \n",
       "6.0     0.744638  0.888553  0.949304  0.954284  0.944417  0.894503  0.956138   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "1599.0  0.260584  0.100707  0.116248  0.088784  0.337562  0.502196  0.103488   \n",
       "1690.0  0.257719  0.093857  0.107055  0.079984  0.328262  0.498289  0.093525   \n",
       "1760.0  0.251844  0.082882  0.098280  0.071199  0.320292  0.495036  0.079171   \n",
       "1813.0  0.245281  0.071562  0.092644  0.064950  0.311957  0.486170  0.068015   \n",
       "2029.0  0.006550  0.010198  0.009924  0.010060  0.008693  0.005954  0.010294   \n",
       "\n",
       "            7         8         9     ...      2652      2653      2654  \\\n",
       "0.0     0.999091  0.999518  0.999997  ...  0.999942  0.999892  0.998878   \n",
       "3.0     0.992223  0.994270  0.996848  ...  0.989032  0.997803  0.991950   \n",
       "4.0     0.979665  0.980709  0.970878  ...  0.972543  0.972053  0.978847   \n",
       "5.0     0.966981  0.963457  0.939818  ...  0.960980  0.932772  0.963786   \n",
       "6.0     0.958616  0.953538  0.919636  ...  0.952272  0.917319  0.953391   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "1599.0  0.100280  0.135626  0.665883  ...  0.341956  0.260377  0.090854   \n",
       "1690.0  0.091284  0.126850  0.663059  ...  0.333463  0.255011  0.081370   \n",
       "1760.0  0.082216  0.120120  0.661010  ...  0.326241  0.246574  0.074152   \n",
       "1813.0  0.075951  0.113942  0.655532  ...  0.318321  0.237883  0.068123   \n",
       "2029.0  0.009814  0.009751  0.003956  ...  0.008574  0.008832  0.009708   \n",
       "\n",
       "            2655      2656      2657      2658      2659      2660      2661  \n",
       "0.0     0.998989  0.999961  0.998592  0.999974  0.999376  0.997172  0.999805  \n",
       "3.0     0.991956  0.997363  0.987516  0.996628  0.991377  0.988204  0.970640  \n",
       "4.0     0.978636  0.982502  0.974065  0.962700  0.955129  0.974229  0.936413  \n",
       "5.0     0.966515  0.963416  0.961725  0.910919  0.915803  0.960137  0.919683  \n",
       "6.0     0.958142  0.952575  0.951420  0.872813  0.884279  0.947830  0.908099  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "1599.0  0.096821  0.439469  0.079623  0.386224  0.104125  0.061292  0.154872  \n",
       "1690.0  0.087851  0.432493  0.069468  0.381994  0.098139  0.052284  0.145442  \n",
       "1760.0  0.076273  0.426117  0.061536  0.376748  0.088860  0.042003  0.137495  \n",
       "1813.0  0.068728  0.415024  0.055502  0.364445  0.079687  0.034986  0.132789  \n",
       "2029.0  0.010019  0.007552  0.009818  0.007157  0.009407  0.010137  0.009871  \n",
       "\n",
       "[109 rows x 2662 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surv_test_df = deephit_model.predict_surv_df(X_test_np, batch_size=batch_size)\n",
    "surv_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a6175b-2ebc-4af4-b6f1-a567f9bf079e",
   "metadata": {},
   "source": [
    "If you want to interpolate, PyCox provides the following interpolation functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2444a50e-7836-4a05-b011-a3b7d0b5029f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2652</th>\n",
       "      <th>2653</th>\n",
       "      <th>2654</th>\n",
       "      <th>2655</th>\n",
       "      <th>2656</th>\n",
       "      <th>2657</th>\n",
       "      <th>2658</th>\n",
       "      <th>2659</th>\n",
       "      <th>2660</th>\n",
       "      <th>2661</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999319</td>\n",
       "      <td>0.999421</td>\n",
       "      <td>0.998916</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999029</td>\n",
       "      <td>0.999091</td>\n",
       "      <td>0.999518</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.998878</td>\n",
       "      <td>0.998989</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.998592</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999376</td>\n",
       "      <td>0.997172</td>\n",
       "      <td>0.999805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.996622</td>\n",
       "      <td>0.998395</td>\n",
       "      <td>0.998434</td>\n",
       "      <td>0.998143</td>\n",
       "      <td>0.998619</td>\n",
       "      <td>0.999673</td>\n",
       "      <td>0.998214</td>\n",
       "      <td>0.998404</td>\n",
       "      <td>0.998993</td>\n",
       "      <td>0.999682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998851</td>\n",
       "      <td>0.999683</td>\n",
       "      <td>0.998186</td>\n",
       "      <td>0.998286</td>\n",
       "      <td>0.999701</td>\n",
       "      <td>0.997485</td>\n",
       "      <td>0.999639</td>\n",
       "      <td>0.998576</td>\n",
       "      <td>0.996275</td>\n",
       "      <td>0.996888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.993262</td>\n",
       "      <td>0.997471</td>\n",
       "      <td>0.997447</td>\n",
       "      <td>0.997371</td>\n",
       "      <td>0.997293</td>\n",
       "      <td>0.999359</td>\n",
       "      <td>0.997399</td>\n",
       "      <td>0.997717</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.999367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997760</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>0.997493</td>\n",
       "      <td>0.997583</td>\n",
       "      <td>0.999441</td>\n",
       "      <td>0.996377</td>\n",
       "      <td>0.999305</td>\n",
       "      <td>0.997776</td>\n",
       "      <td>0.995378</td>\n",
       "      <td>0.993972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.989903</td>\n",
       "      <td>0.996547</td>\n",
       "      <td>0.996460</td>\n",
       "      <td>0.996598</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.999044</td>\n",
       "      <td>0.996584</td>\n",
       "      <td>0.997031</td>\n",
       "      <td>0.997944</td>\n",
       "      <td>0.999052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996669</td>\n",
       "      <td>0.999266</td>\n",
       "      <td>0.996800</td>\n",
       "      <td>0.996879</td>\n",
       "      <td>0.999181</td>\n",
       "      <td>0.995269</td>\n",
       "      <td>0.998970</td>\n",
       "      <td>0.996976</td>\n",
       "      <td>0.994481</td>\n",
       "      <td>0.991055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.986543</td>\n",
       "      <td>0.995623</td>\n",
       "      <td>0.995472</td>\n",
       "      <td>0.995826</td>\n",
       "      <td>0.994643</td>\n",
       "      <td>0.998729</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.996344</td>\n",
       "      <td>0.997419</td>\n",
       "      <td>0.998737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995578</td>\n",
       "      <td>0.999057</td>\n",
       "      <td>0.996107</td>\n",
       "      <td>0.996176</td>\n",
       "      <td>0.998922</td>\n",
       "      <td>0.994162</td>\n",
       "      <td>0.998635</td>\n",
       "      <td>0.996176</td>\n",
       "      <td>0.993585</td>\n",
       "      <td>0.988139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942.6</th>\n",
       "      <td>0.102042</td>\n",
       "      <td>0.034743</td>\n",
       "      <td>0.043012</td>\n",
       "      <td>0.032016</td>\n",
       "      <td>0.129998</td>\n",
       "      <td>0.198041</td>\n",
       "      <td>0.033382</td>\n",
       "      <td>0.036269</td>\n",
       "      <td>0.051427</td>\n",
       "      <td>0.264587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132473</td>\n",
       "      <td>0.100452</td>\n",
       "      <td>0.033074</td>\n",
       "      <td>0.033503</td>\n",
       "      <td>0.170541</td>\n",
       "      <td>0.028092</td>\n",
       "      <td>0.150072</td>\n",
       "      <td>0.037519</td>\n",
       "      <td>0.020077</td>\n",
       "      <td>0.059038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964.2</th>\n",
       "      <td>0.078169</td>\n",
       "      <td>0.028607</td>\n",
       "      <td>0.034740</td>\n",
       "      <td>0.026527</td>\n",
       "      <td>0.099671</td>\n",
       "      <td>0.150019</td>\n",
       "      <td>0.027610</td>\n",
       "      <td>0.029655</td>\n",
       "      <td>0.041008</td>\n",
       "      <td>0.199429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101498</td>\n",
       "      <td>0.077547</td>\n",
       "      <td>0.027233</td>\n",
       "      <td>0.027632</td>\n",
       "      <td>0.129794</td>\n",
       "      <td>0.023524</td>\n",
       "      <td>0.114343</td>\n",
       "      <td>0.030491</td>\n",
       "      <td>0.017592</td>\n",
       "      <td>0.046746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985.8</th>\n",
       "      <td>0.054296</td>\n",
       "      <td>0.022470</td>\n",
       "      <td>0.026468</td>\n",
       "      <td>0.021038</td>\n",
       "      <td>0.069345</td>\n",
       "      <td>0.101997</td>\n",
       "      <td>0.021838</td>\n",
       "      <td>0.023041</td>\n",
       "      <td>0.030589</td>\n",
       "      <td>0.134272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070524</td>\n",
       "      <td>0.054642</td>\n",
       "      <td>0.021392</td>\n",
       "      <td>0.021761</td>\n",
       "      <td>0.089047</td>\n",
       "      <td>0.018955</td>\n",
       "      <td>0.078614</td>\n",
       "      <td>0.023463</td>\n",
       "      <td>0.015107</td>\n",
       "      <td>0.034454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007.4</th>\n",
       "      <td>0.030423</td>\n",
       "      <td>0.016334</td>\n",
       "      <td>0.018197</td>\n",
       "      <td>0.015549</td>\n",
       "      <td>0.039019</td>\n",
       "      <td>0.053976</td>\n",
       "      <td>0.016066</td>\n",
       "      <td>0.016428</td>\n",
       "      <td>0.020170</td>\n",
       "      <td>0.069114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039549</td>\n",
       "      <td>0.031737</td>\n",
       "      <td>0.015550</td>\n",
       "      <td>0.015890</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.014387</td>\n",
       "      <td>0.042886</td>\n",
       "      <td>0.016435</td>\n",
       "      <td>0.012622</td>\n",
       "      <td>0.022162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029.0</th>\n",
       "      <td>0.006550</td>\n",
       "      <td>0.010198</td>\n",
       "      <td>0.009925</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>0.010294</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>0.009751</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008574</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>0.007552</td>\n",
       "      <td>0.009818</td>\n",
       "      <td>0.007157</td>\n",
       "      <td>0.009407</td>\n",
       "      <td>0.010137</td>\n",
       "      <td>0.009871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1081 rows  2662 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6     \\\n",
       "0.0     0.999981  0.999319  0.999421  0.998916  0.999944  0.999988  0.999029   \n",
       "0.3     0.996622  0.998395  0.998434  0.998143  0.998619  0.999673  0.998214   \n",
       "0.6     0.993262  0.997471  0.997447  0.997371  0.997293  0.999359  0.997399   \n",
       "0.9     0.989903  0.996547  0.996460  0.996598  0.995968  0.999044  0.996584   \n",
       "1.2     0.986543  0.995623  0.995472  0.995826  0.994643  0.998729  0.995768   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "1942.6  0.102042  0.034743  0.043012  0.032016  0.129998  0.198041  0.033382   \n",
       "1964.2  0.078169  0.028607  0.034740  0.026527  0.099671  0.150019  0.027610   \n",
       "1985.8  0.054296  0.022470  0.026468  0.021038  0.069345  0.101997  0.021838   \n",
       "2007.4  0.030423  0.016334  0.018197  0.015549  0.039019  0.053976  0.016066   \n",
       "2029.0  0.006550  0.010198  0.009925  0.010061  0.008692  0.005954  0.010294   \n",
       "\n",
       "            7         8         9     ...      2652      2653      2654  \\\n",
       "0.0     0.999091  0.999518  0.999997  ...  0.999942  0.999892  0.998878   \n",
       "0.3     0.998404  0.998993  0.999682  ...  0.998851  0.999683  0.998186   \n",
       "0.6     0.997717  0.998468  0.999367  ...  0.997760  0.999475  0.997493   \n",
       "0.9     0.997031  0.997944  0.999052  ...  0.996669  0.999266  0.996800   \n",
       "1.2     0.996344  0.997419  0.998737  ...  0.995578  0.999057  0.996107   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "1942.6  0.036269  0.051427  0.264587  ...  0.132473  0.100452  0.033074   \n",
       "1964.2  0.029655  0.041008  0.199429  ...  0.101498  0.077547  0.027233   \n",
       "1985.8  0.023041  0.030589  0.134272  ...  0.070524  0.054642  0.021392   \n",
       "2007.4  0.016428  0.020170  0.069114  ...  0.039549  0.031737  0.015550   \n",
       "2029.0  0.009814  0.009751  0.003956  ...  0.008574  0.008832  0.009709   \n",
       "\n",
       "            2655      2656      2657      2658      2659      2660      2661  \n",
       "0.0     0.998989  0.999961  0.998592  0.999974  0.999376  0.997172  0.999805  \n",
       "0.3     0.998286  0.999701  0.997485  0.999639  0.998576  0.996275  0.996888  \n",
       "0.6     0.997583  0.999441  0.996377  0.999305  0.997776  0.995378  0.993972  \n",
       "0.9     0.996879  0.999181  0.995269  0.998970  0.996976  0.994481  0.991055  \n",
       "1.2     0.996176  0.998922  0.994162  0.998635  0.996176  0.993585  0.988139  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "1942.6  0.033503  0.170541  0.028092  0.150072  0.037519  0.020077  0.059038  \n",
       "1964.2  0.027632  0.129794  0.023524  0.114343  0.030491  0.017592  0.046746  \n",
       "1985.8  0.021761  0.089047  0.018955  0.078614  0.023463  0.015107  0.034454  \n",
       "2007.4  0.015890  0.048300  0.014387  0.042886  0.016435  0.012622  0.022162  \n",
       "2029.0  0.010019  0.007552  0.009818  0.007157  0.009407  0.010137  0.009871  \n",
       "\n",
       "[1081 rows x 2662 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we interpolate by a factor of 10 (so that if we initially had m time steps, we would now have (m-1)*10 + 1 time steps)\n",
    "interpolation_factor = 10\n",
    "surv_test_interp_df = deephit_model.interpolate(interpolation_factor).predict_surv_df(X_test_np, batch_size=batch_size)\n",
    "surv_test_interp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "585df8ae-b1ee-4188-9eeb-79493940f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_grid_train_interp_np = surv_test_interp_df.index.to_numpy()  # the interpolated time grid is an interpolated version of the *training*  time grid\n",
    "surv_test_interp_np = surv_test_interp_df.to_numpy().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d1cae8-1d0c-4360-9c22-77e7facfd4ab",
   "metadata": {},
   "source": [
    "We point out that if one did not want to create a Pandas DataFrame first, then the following code could be used instead to produce the same interpolated time grid and interpolated survival function:\n",
    "\n",
    "```\n",
    "surv_test_interp_np = deephit_model.interpolate(interpolation_factor).predict_surv(X_test_np, batch_size=batch_size, to_cpu=True, numpy=True)\n",
    "from pycox.models.utils import make_subgrid\n",
    "time_grid_train_interp_np = np.array(make_subgrid(time_grid_train_np, interpolation_factor))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639331f2-90fd-48ee-a96c-4f9fe03aeffc",
   "metadata": {},
   "source": [
    "Here's a plot of the predicted survival function for the 0th test data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1bc9c26-471b-471d-8100-9f88af2c90bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Survival probability')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABI0ElEQVR4nO3deXhTZd4+8Ptk75Kk+0YLlL3sUBQoIopjBVllVFRmwEGdqRub+iryk210UMdBVASdgTr6Diqjg4ojr1IVKatCKYK0bFJoC10o0KRr1vP7I20gtEBTkp4kvT/XlavtyTnJ9+G05vZ5nvMcQRRFEUREREQBQiZ1AURERESexHBDREREAYXhhoiIiAIKww0REREFFIYbIiIiCigMN0RERBRQGG6IiIgooCikLqCt2e12nDlzBlqtFoIgSF0OERERtYAoiqiqqkJCQgJksqv3zbS7cHPmzBkkJSVJXQYRERG1QlFRERITE6+6T7sLN1qtFoDjH0en00lcDREREbWE0WhEUlKS83P8atpduGkcitLpdAw3REREfqYlU0o4oZiIiIgCCsMNERERBRSGGyIiIgooDDdEREQUUBhuiIiIKKAw3BAREVFAYbghIiKigMJwQ0RERAGF4YaIiIgCCsMNERERBRRJw012djYmTJiAhIQECIKAzz///JrHbN26FampqdBoNOjSpQveeecd7xdKREREfkPScFNTU4MBAwZg5cqVLdq/oKAAd955J0aOHInc3Fw8//zzmDVrFv7zn/94uVIiIiLyF5LeOHPs2LEYO3Zsi/d/55130LFjR6xYsQIAkJKSgr179+K1117Db3/7Wy9V2TI2u4iKahNqzTYkR4VIWgsREVF75ldzbnbt2oX09HSXbXfccQf27t0Li8XS7DEmkwlGo9Hl4Q1nKusw9C/fYcyKbK+8PhEREbWMX4Wb0tJSxMbGumyLjY2F1WpFRUVFs8csW7YMer3e+UhKSvJKbTqNEgBgstphttq98h5ERER0bX4VbgBAEASXn0VRbHZ7o/nz58NgMDgfRUVFXqkrVHNxhK+qvvleJCIiIvI+SefcuCsuLg6lpaUu28rLy6FQKBAZGdnsMWq1Gmq12uu1yWUCQlRy1JhtqKq3IjLU++9JRERETflVz83w4cORlZXlsm3z5s0YMmQIlEqlRFVdpAty1FBVb5W4EiIiovZL0nBTXV2N/fv3Y//+/QAcl3rv378fhYWFABxDStOnT3fun5GRgVOnTmHevHnIz89HZmYm1q5di6efflqK8pvQNgxNcViKiIhIOpIOS+3duxe33nqr8+d58+YBAGbMmIF//vOfKCkpcQYdAEhOTsamTZswd+5cvP3220hISMCbb74p+WXgjbQNk4qN7LkhIiKSjKTh5pZbbnFOCG7OP//5zybbRo0ahX379nmxqtZr7LkxsueGiIhIMn4158bXNfbccM4NERGRdBhuPIhzboiIiKTHcONBF8MNe26IiIikwnDjQTrnsBR7boiIiKTCcONBwSo5AKDWbJO4EiIiovaL4caD5DLHLSDsV7kCjIiIiLyL4caDGu9vZed9M4mIiCTDcONBcoE9N0RERFJjuPGghlEp2JltiIiIJMNw40Ey9twQERFJjuHGg2ScUExERCQ5hhsP4rAUERGR9BhuPMg5LMV0Q0REJBmGGw8SnD03DDdERERSYbjxIC7iR0REJD2GGw+6eLWUxIUQERG1Yww3HuScUMx0Q0REJBmGGw/iOjdERETSY7jxIA5LERERSY/hxoNkDf+a7LkhIiKSDsONBwkcliIiIpIcw40HOe8Kbpe4ECIionaM4caDOKGYiIhIegw3HiTjCsVERESSY7jxoIt3BZe4ECIionaM4caDOCxFREQkPYYbD+IKxURERNJjuPEgDksRERFJj+HGgzgsRUREJD2GGw/isBQREZH0GG48iPeWIiIikh7DjQdxWIqIiEh6DDcedPHGmdLWQURE1J4x3HgQe26IiIikx3DjQQw3RERE0mO48SBeLUVERCQ9hhsP4tVSRERE0mO48SAOSxEREUmP4caDLl4txXBDREQkFYYbD+KwFBERkfQYbjzIGW6YboiIiCTDcONBHJYiIiKSHsONB3FYioiISHoMNx7UGG4ADk0RERFJheHGg+SXhhsOTREREUmC4caDhEv+NdlxQ0REJA2GGw+SseeGiIhIcgw3HiS7mG0YboiIiCTCcONBrj03EhZCRETUjjHceBCHpYiIiKTHcONBLsNS7LohIiKSBMONB8llHJYiIiKSGsONBwkcliIiIpIcw42HNXbecFiKiIhIGgw3Hsb7SxEREUmL4cbDZLLGcMN0Q0REJAWGGw9zDksx3BAREUlC8nCzatUqJCcnQ6PRIDU1Fdu2bbvq/uvWrcOAAQMQHByM+Ph4/OEPf8C5c+faqNprcw5L2SUuhIiIqJ2SNNysX78ec+bMwYIFC5Cbm4uRI0di7NixKCwsbHb/7du3Y/r06XjooYdw6NAhfPLJJ9izZw8efvjhNq78yuQCh6WIiIikJGm4Wb58OR566CE8/PDDSElJwYoVK5CUlITVq1c3u//u3bvRuXNnzJo1C8nJybjpppvwpz/9CXv37m3jyq9M4LAUERGRpCQLN2azGTk5OUhPT3fZnp6ejp07dzZ7TFpaGoqLi7Fp0yaIooiysjJ8+umnGDdu3BXfx2QywWg0ujy8iROKiYiIpCVZuKmoqIDNZkNsbKzL9tjYWJSWljZ7TFpaGtatW4epU6dCpVIhLi4OYWFheOutt674PsuWLYNer3c+kpKSPNqOyzUOS9k454aIiEgSkk8ovnRVXwAQRbHJtkZ5eXmYNWsWFi5ciJycHHz99dcoKChARkbGFV9//vz5MBgMzkdRUZFH67+cwDk3REREklJI9cZRUVGQy+VNemnKy8ub9OY0WrZsGUaMGIFnnnkGANC/f3+EhIRg5MiRePHFFxEfH9/kGLVaDbVa7fkGXIG8IS7auIofERGRJCTruVGpVEhNTUVWVpbL9qysLKSlpTV7TG1tLWQy15LlcjkAR4+PL+DVUkRERNKSdFhq3rx5WLNmDTIzM5Gfn4+5c+eisLDQOcw0f/58TJ8+3bn/hAkTsGHDBqxevRonTpzAjh07MGvWLNx4441ISEiQqhkuGicUs+eGiIhIGpINSwHA1KlTce7cOSxduhQlJSXo27cvNm3ahE6dOgEASkpKXNa8efDBB1FVVYWVK1fiqaeeQlhYGEaPHo1XXnlFqiY0IefVUkRERJISRF8Zz2kjRqMRer0eBoMBOp3O468/+rUfcKKiBv/+03DcmBzh8dcnIiJqj9z5/Jb8aqlAw2EpIiIiaTHceBgnFBMREUmL4cbDGnturOy5ISIikgTDjYc1rnNjZ7ghIiKSBMONh128/QLDDRERkRQYbjzMOaGYc26IiIgkwXDjYc4Jxey5ISIikgTDjYex54aIiEhaDDcexjk3RERE0mK48TDefoGIiEhaDDcednGFYokLISIiaqcYbjxM7sg2nFBMREQkEYYbD5NzQjEREZGkGG48TMYJxURERJJiuPEwTigmIiKSFsONh12cUMxwQ0REJAWGGw/jOjdERETSYrjxMA5LERERSYvhxsMuTiiWuBAiIqJ2iuHGw+QN/6LsuSEiIpIGw42HyTmhmIiISFIMNx7GdW6IiIikxXDjYZxQTEREJC2GGw9jzw0REZG0GG48jPeWIiIikhbDjYcpGsONjeGGiIhICgw3HqZWOP5JTVYudENERCQFt8PN4sWLcerUKW/UEhDUSjkAwGS1SVwJERFR++R2uPnyyy/RtWtX3Hbbbfjwww9RX1/vjbr8FntuiIiIpOV2uMnJycG+ffvQv39/zJ07F/Hx8Xj00UexZ88eb9Tndxp7buot7LkhIiKSQqvm3PTv3x+vv/46Tp8+jczMTJw+fRojRoxAv3798MYbb8BgMHi6Tr/BnhsiIiJpXdeEYrvdDrPZDJPJBFEUERERgdWrVyMpKQnr16/3VI1+RdM458bCcENERCSFVoWbnJwcPPHEE4iPj8fcuXMxaNAg5OfnY+vWrTh8+DAWLVqEWbNmebpWv3Cx54bDUkRERFJwO9z0798fw4YNQ0FBAdauXYuioiK8/PLL6Natm3Of6dOn4+zZsx4t1F80hpt69twQERFJQuHuAffccw9mzpyJDh06XHGf6Oho2O3t88NdreCl4ERERFJyu+dGFEWEh4c32V5XV4elS5d6pCh/plFyQjEREZGU3A43S5YsQXV1dZPttbW1WLJkiUeK8meNPTccliIiIpJGq3puhIY7X1/q559/RkREhEeK8mdqJScUExERSanFc27Cw8MhCAIEQUCPHj1cAo7NZkN1dTUyMjK8UqQ/cV4KzmEpIiIiSbQ43KxYsQKiKGLmzJlYsmQJ9Hq98zmVSoXOnTtj+PDhXinSnzReLWW22mG3i5DJmvZyERERkfe0ONzMmDEDAJCcnIy0tDQolUqvFeXPGsMNAJhtdmhkcgmrISIian9aFG6MRiN0Oh0AYNCgQairq0NdXV2z+zbu1141DksBjlWKL/2ZiIiIvK9F4SY8PBwlJSWIiYlBWFhYsxOKGyca22zteyKtQiZAJgB2Eai32qAHe7iIiIjaUovCzffff++8EmrLli1eLcjfCYIAtUKOOouN95ciIiKSQIvCzahRo5r9npqnUcoc4YaXgxMREbW5FoWbAwcOtPgF+/fv3+piAoVjIT8LF/IjIiKSQIvCzcCBAyEIAkRRvOp+nHPjwIX8iIiIpNOicFNQUODtOgKKRsGF/IiIiKTSonDTqVMnb9cRUNhzQ0REJJ0WhZuNGzdi7NixUCqV2Lhx41X3nThxokcK82eNC/lxzg0REVHba1G4mTx5MkpLSxETE4PJkydfcT/OuXG4eH8p/lsQERG1tRaFG7vd3uz31LzGnhuuc0NERNT2ZNfehdylbphQXGdhzw0REVFba1W4+e677zB+/Hh07doV3bp1w/jx4/Htt996uja/FRbsuOXChVqLxJUQERG1P26Hm5UrV2LMmDHQarWYPXs2Zs2aBZ1OhzvvvBMrV670Ro1+J1qrBgCcrTJJXAkREVH706I5N5datmwZXn/9dTzxxBPObbNmzcKIESPw0ksvuWxvrxhuiIiIpON2z43RaMSYMWOabE9PT4fRaPRIUf5OH+QYlqqq57AUERFRW3M73EycOBGfffZZk+1ffPEFJkyY4HYBq1atQnJyMjQaDVJTU7Ft27ar7m8ymbBgwQJ06tQJarUaXbt2RWZmptvv602hakeHWFW9VeJKiIiI2p8WDUu9+eabzu9TUlLw0ksv4YcffsDw4cMBALt378aOHTvw1FNPufXm69evx5w5c7Bq1SqMGDEC7777LsaOHYu8vDx07Nix2WPuvfdelJWVYe3atejWrRvKy8thtfpWiNBqHP+s1SbfqouIiKg9EMRr3Q0TQHJycsteTBBw4sSJFr/50KFDMXjwYKxevdq5LSUlBZMnT8ayZcua7P/111/jvvvuw4kTJxAREdGi9zCZTDCZLs59MRqNSEpKgsFggE6na3Gt7jhaVoX017MREaLCvhdu98p7EBERtSdGoxF6vb5Fn9+S3TjTbDYjJycHzz33nMv29PR07Ny5s9ljNm7ciCFDhuDVV1/F//7v/yIkJAQTJ07En//8ZwQFBTV7zLJly7BkyRKP1381F4elLBBFEYIgtOn7ExERtWduXy3lKRUVFbDZbIiNjXXZHhsbi9LS0maPOXHiBLZv3w6NRoPPPvsMFRUVeOyxx3D+/PkrzruZP38+5s2b5/y5sefGm0IbhqUsNhEmq915OwYiIiLyvlaFm+LiYmzcuBGFhYUwm80uzy1fvtyt17q8V+NqPR12ux2CIGDdunXQ6/XO97v77rvx9ttvN9t7o1aroVar3arpeoWoLv6zGustDDdERERtyO1w891332HixIlITk7GkSNH0LdvX5w8eRKiKGLw4MEtfp2oqCjI5fImvTTl5eVNenMaxcfHo0OHDs5gAzjm6IiiiOLiYnTv3t3d5niFXCYgKlSNimoTygwmxGg1UpdERETUbrh9Kfj8+fPx1FNP4ZdffoFGo8F//vMfFBUVYdSoUbjnnnta/DoqlQqpqanIyspy2Z6VlYW0tLRmjxkxYgTOnDmD6upq57ajR49CJpMhMTHR3aZ4VYdwRy/S6cpaiSshIiJqX9wON/n5+ZgxYwYAQKFQoK6uDqGhoVi6dCleeeUVt15r3rx5WLNmDTIzM5Gfn4+5c+eisLAQGRkZABxBavr06c79H3jgAURGRuIPf/gD8vLykJ2djWeeeQYzZ8684oRiqSQ2hJviC3USV0JERNS+uD0sFRIS4ry0OiEhAb/++iv69OkDwDFJ2B1Tp07FuXPnsHTpUpSUlKBv377YtGkTOnXqBAAoKSlBYWGhc//Q0FBkZWXhySefxJAhQxAZGYl7770XL774orvN8LrEsMaeG4YbIiKituR2uBk2bBh27NiB3r17Y9y4cXjqqadw8OBBbNiwAcOGDXO7gMceewyPPfZYs8/985//bLKtV69eTYayfFGc3jHPptzI+0sRERG1JbfDzfLly51zXhYvXozq6mqsX78e3bp1w+uvv+7xAv1VeLAKAFBZZ77GnkRERORJboebLl26OL8PDg7GqlWrPFpQoAgLdtw880INb55JRETUllq9iN/evXuRn58PQRCQkpKC1NRUT9bl98Iae25q2XNDRETUltwON8XFxbj//vuxY8cOhIWFAQAqKyuRlpaGjz76yOur//qL8Maem1r23BAREbUlty8FnzlzJiwWC/Lz83H+/HmcP38e+fn5EEURDz30kDdq9EuNPTd1FhvqLTaJqyEiImo/3O652bZtG3bu3ImePXs6t/Xs2RNvvfUWRowY4dHi/JlOo4BcJsBmF1FZa0GcnrdgICIiagtu99x07NgRFkvToRar1YoOHTp4pKhAIAgCwoIah6Y474aIiKituB1uXn31VTz55JPYu3cvRFEE4JhcPHv2bLz22mseL9CfOa+YYrghIiJqMy0algoPD3e5U3dNTQ2GDh0KhcJxuNVqhUKhwMyZMzF58mSvFOqPHGvd1KCSk4qJiIjaTIvCzYoVK7xcRmCKCHFMKj5XzVWKiYiI2kqLwk3jjTLJPQkN95cq5v2liIiI2kyrFvGz2Wz4/PPPnYv49e7dGxMnToRcziuCLsU7gxMREbU9t8PN8ePHceedd+L06dPo2bMnRFHE0aNHkZSUhK+++gpdu3b1Rp1+KSkiGADDDRERUVty+2qpWbNmoWvXrigqKsK+ffuQm5uLwsJCJCcnY9asWd6o0W819tycvlArcSVERETth9s9N1u3bsXu3bsRERHh3BYZGYmXX36Zi/hdJjHc0XNTUW1GndmGIBWH7YiIiLzN7Z4btVqNqqqqJturq6uhUqk8UlSg0AcpoVU78uNpTiomIiJqE26Hm/Hjx+OPf/wjfvzxR4iiCFEUsXv3bmRkZGDixIneqNGvdWgcmmK4ISIiahNuh5s333wTXbt2xfDhw6HRaKDRaDBixAh069YNb7zxhjdq9Gsdwhrn3TDcEBERtQW35tyIogiDwYCPPvoIZ86ccd4NvHfv3ujWrZu3avRrjWvdnGHPDRERUZtwO9x0794dhw4dQvfu3RloWqAx3HBYioiIqG24NSwlk8nQvXt3nDt3zlv1BBzOuSEiImpbrbor+DPPPINffvnFG/UEnA5hGgCcc0NERNRW3F7n5ne/+x1qa2sxYMAAqFQqBAUFuTx//vx5jxUXCBqHpUqN9bDZRchlwjWOICIiouvhdrjhHcLdE6PVQCETYLWLKDPWO8MOEREReYfb4YZ3CHePXCYgTq9B8YU6FJ6vZbghIiLyslbfFfyzzz5z3hU8JSUFkyZNgkLRqpcLeH0SdCi+UIecUxcwrEuk1OUQEREFNLfTyC+//IJJkyahtLQUPXv2BAAcPXoU0dHR2LhxI/r16+fxIv3d8C6R+OZQGXafOIfHb+Xl80RERN7k9tVSDz/8MPr06YPi4mLs27cP+/btQ1FREfr3748//vGP3qjR7w3vGgUA2HvyAsxWu8TVEBERBTa3e25+/vln7N27F+Hh4c5t4eHheOmll3DDDTd4tLhA0T0mFBEhKpyvMeNAcSWGdI649kFERETUKm733PTs2RNlZWVNtpeXl3PF4iuQyQQM6+IINLt+5QKIRERE3uR2uPnLX/6CWbNm4dNPP0VxcTGKi4vx6aefYs6cOXjllVdgNBqdD7poeMNE4l0nGG6IiIi8SRBFUXTnAJnsYh4SBMeCdI0vcenPgiDAZrN5qk6PMRqN0Ov1MBgM0Ol0bfa+x8ur8Jvl2VArZDiwOB1qhbzN3puIiMjfufP57facmy1btrS6sPasa3QookLVqKg2Yd+pSgzvykvCiYiIvMHtcDNq1Chv1BHwBEHAzd2jsCH3NP574AzDDRERkZe4PeeGWm9YQ6Ap5k00iYiIvIbhpg1FBKsAAJW1ZokrISIiClwMN20oPEQJALhQa5G4EiIiosDFcNOG9EGOnpsL7LkhIiLyGoabNhQe7Oi5qaq3wmrjbRiIiIi8oUVXSw0aNMi5hs217Nu377oKCmT6IKXz+8o6C6JC1RJWQ0REFJhaFG4mT57s5TLaB4VcBp1GAWO9FYfOGDGqR7TUJREREQUct1co9ndSrVDc6IkP9+G/B0oQFarCjudGc6ViIiKiFnDn85tzbtrYq3f3R4xWjYpqM7YdrZC6HCIiooDjdrix2Wx47bXXcOONNyIuLg4REREuD7q6YJUC4/snAAC+PHBG4mqIiIgCj9vhZsmSJVi+fDnuvfdeGAwGzJs3D1OmTIFMJsPixYu9UGLgmTjQEW42HSzBzl/Ze0NERORJboebdevW4R//+AeefvppKBQK3H///VizZg0WLlyI3bt3e6PGgDMgUY9be0bDYhPxpw9yUGOySl0SERFRwHA73JSWlqJfv34AgNDQUBgMBgDA+PHj8dVXX3m2ugAlCALeuH8QwoKVqDJZ8d3hcqlLIiIiChhuh5vExESUlJQAALp164bNmzcDAPbs2QO1muu2tJROo8TvhnYCAHy2r1jiaoiIiAKH2+HmrrvuwnfffQcAmD17Nl544QV0794d06dPx8yZMz1eYCCbPKgDZAKw5chZfJdfJnU5REREAeG617n58ccfsWPHDnTr1g0TJ070VF1eI/U6N5f7y6Z8/D37BBL0Gnz55E2I5KrFRERETbjz+e12uKmtrUVwcPB1FSglXws3tWYr7liRjaLzdegVp8WGx9IQrGrRwtFERETthlcX8YuJicHvfvc7fPPNN7DbefPH6xWsUuCff7gRUaFqHC6twr/3FEldEhERkV9zO9x88MEHMJlMuOuuu5CQkIDZs2djz5493qit3egaHYrZt3UDALy38yRs9nZ1RwwiIiKPcjvcTJkyBZ988gnKysqwbNky5OfnIy0tDT169MDSpUu9UWO78NvUROiDlDh1rhazP85FiaFO6pKIiIj8kkdunJmXl4dp06bhwIEDsNlsnqjLa3xtzs2lPvqpEM9/dhCiCKgVMrx2zwBMGJAgdVlERESSa5MbZ9bX1+Pf//43Jk+ejMGDB+PcuXN4+umnW/tyBOD+Gzvi04zhuKFzOExWO578KBeZ2wukLouIiMivuB1uNm/ejBkzZiA2NhYZGRmIiYnBN998g8LCQrzyyituF7Bq1SokJydDo9EgNTUV27Zta9FxO3bsgEKhwMCBA91+T1+W2ikCH/9xOGYMdyzwt/S/eXjuPwdQfKFW4sqIiIj8g9vhZvLkyaitrcX777+PsrIy/P3vf8eoUaNa9ebr16/HnDlzsGDBAuTm5mLkyJEYO3YsCgsLr3qcwWDA9OnTcdttt7XqfX2dXCZg8cQ+eOaOngCAj/cUYdRff8Dfs3+VuDIiIiLf5/acG6PR6LG5KkOHDsXgwYOxevVq57aUlBRMnjwZy5Ytu+Jx9913H7p37w65XI7PP/8c+/fvb/F7+vKcm+bs+vUc3t5yHNuPO+4evnB8b8xI6wy5TJC4MiIiorbj8Tk3RqOxyc9XerSU2WxGTk4O0tPTXbanp6dj586dVzzuvffew6+//opFixa16H1MJlOra/QFw7tG4l8PD8Ws0Y5LxZf+Nw8jX/ke3xwqlbgyIiIi39SipXDDw8NRUlKCmJgYhIWFQRCa9hqIoghBEFp8tVRFRQVsNhtiY2NdtsfGxqK0tPkP7mPHjuG5557Dtm3boFC0bBXfZcuWYcmSJS3a15fNvb0HVAoZ/p59AmcM9Xh83T4snNAbUwYnIlTNFY2JiIgatehT8fvvv0dERITz++bCTWtd/lqNIelyNpsNDzzwAJYsWYIePXq0+PXnz5+PefPmOX82Go1ISkpqfcESEQQBT4zujodHdsH8DQfxWe5pLPziEF7+v8N4cnR3PDwyGUp5qy9+IyIiChgeWeemNcxmM4KDg/HJJ5/grrvucm6fPXs29u/fj61bt7rsX1lZifDwcMjlcuc2u90OURQhl8uxefNmjB49+prv629zbppjtdmRuaMAH/9UhBMVNQCA7jGhmHpDEu69IQk6jVLiComIiDzLq+vcdOnSBS+88AKOHDnS6gIBQKVSITU1FVlZWS7bs7KykJaW1mR/nU6HgwcPYv/+/c5HRkYGevbsif3792Po0KHXVY8/Uchl+OPNXfHdU6Pw2j0DEB6sxLHyarz4VT5+v/Yn3r6BiIjaNbfDzRNPPIGvv/4aKSkpSE1NxYoVK1BSUtKqN583bx7WrFmDzMxM5OfnY+7cuSgsLERGRgYAx5DS9OnTHYXKZOjbt6/LIyYmBhqNBn379kVISEiravBngiDg7tREbHn6Fiye0BtajQI/F1Xio5+ufik9ERFRIHM73MybNw979uzB4cOHMX78eKxevRodO3ZEeno6PvjgA7dea+rUqVixYgWWLl2KgQMHIjs7G5s2bUKnTo4F7EpKSq655g0BYcEqPDgiGU+nO9bF+es3R3C2yiRxVURERNLwyJyb3bt349FHH+W9pSRmtdkxceUO5JUYERGiwuO3dsO0oR2hUcqvfTAREZEPa5N7SwHATz/9hDlz5uCuu+7CkSNHcPfdd1/Py9F1UshleH3qQHSJCsH5GjP+/N88TFy5HScbJh0TERG1B2733Bw9ehTr1q3Dhx9+iJMnT+LWW2/FtGnTMGXKFGi1Wm/V6TGB3HPTyGqz49OcYry2+Sgqqk3QahSYNbo7fjesE4JU7MUhIiL/487nt9vhRiaTYciQIXjggQdw3333IS4u7rqKbWvtIdw0KjPW49F/5WBfYSUAIFqrxsM3JWNc/3gkhgdLWxwREZEbvBZubDYb1q5di7vvvtu5qJ+/aU/hBnD04mzIPY03vj2G05V1zu0dwoLQJToEXaJC0CE8CDFaDaK1asRo1YjWqqEPUnp0sUYiIqLr4dWeG41Gg/z8fCQnJ19XkVJpb+GmkdnqGKr6Yv9p7Dl5HtdaCkenUaBbTKjLIyVeh3h9UNsUTEREdAl3Pr/dvilRv379cOLECb8NN+2VSiHDA0M74oGhHWGoteBoeRVOnK3GibM1KDXW42yVCeVVJpytMsFQZ4Gx3op9hZXOIa1GfRJ0uL13LNJ7xyElXsveHSIi8jlu99xs3rwZzz77LP785z8jNTW1yeJ5vt4b0l57btxRb7GhoKIGx8ur8evZahwvdzyOllW59PgkhgchvXcc0vvEYkincCh4bysiIvISr08odh58yf+1u3tXcKkw3LTe+Rozvssvw+a8MmQfPQuT1e58LjxYidG9YpHeJxYpcTpoVDJolHKEqBSQy9i7Q0RE18er4ebyG1pebtSoUe68XJtjuPGMWrMV245VYPOhMnx3uAyVtZZm99NqFLhrUAfcf2NHpMTz35uIiFrHq+HG3zHceJ7VZseekxeQlVeG7w+XobzKhDqLDZf/Zg3qGIb7b+yICf0TuN4OERG5xavhJjs7+6rP33zzze68XJtjuGkboijCZLVj78kL+OinQnxzqBTWhgk7KrkMXaJD0C0mFN1jtOgeG4ruMaHoFBkClYLzdoiIqKk2m3PjfJFL5t5wzg0152yVCZ/kFOHjn4pQeL622X0UMgGdo0LQPSYUyVEh0GqUCFLKEBmqxqie0dBplG1cNRER+QqvhhuDweDys8ViQW5uLl544QW89NJLuO2229yvuA0x3EhLFEUUX6jD8fJqHCuvwrGyahxruBqr2mS94nEqhQy39YrB5EEdcEvPaKgVHNYiImpPJJlzk52djblz5yInJ8cTL+c1DDe+SRRFlBrrnWHn1Lka1JptqLPYcKS0CsfLq537ajUKDO8SieFdIzGsSyR6xmoh4xVZREQBTZJwk5+fjxtuuAHV1dXX3llCDDf+RxRF5JUY8XnuaWz8+QzKjCaX51UKGeJ0GsdDr8GwLpGYMrgDNEr27hARBQqvhpsDBw64/CyKIkpKSvDyyy/DYrFgx44d7lfchhhu/JvNLuLn4krsPnEOu0+cx96T51FrbjrPK1qrxkM3JWPa0I7Qcq4OEZHf8/qEYkEQcPlhw4YNQ2ZmJnr16uV+xW2I4SawWGx2lBrqUWqsR6mhHicravDRT4U4Y6gHAAQp5egUGYxYnQaxOjXidBrE6h29PLENj8gQFYe1iIh8nFfDzalTp1x+lslkiI6Ohkajcb9SCTDcBD6LzY4v9p/B6h+O49ezNdfcXyETEKNVNwk9cXr1xe91GoSo3b4VGxEReQgX8bsKhpv2w24XcfxsNUoM9Sgz1KPM6OjhKTPWo8xoQqmxHhXVpiaLDV5JsEqOGK0a0Y2PUDVidBpEhzp+7hAehOSoECh5jy0iIo/zyl3Bf/zxR5w/fx5jx451bvvggw+waNEi1NTUYPLkyXjrrbegVqtbXzmRB8lkAnrEatEjVnvFfSw2OyqqTSg1uIaeMkM9yqrqG7abUG2yotZsw8lztTh5rvl1egDH5OYesaHoHa9D73gd+iXqMSAxjDcVJSJqQy0ON4sXL8Ytt9ziDDcHDx7EQw89hAcffBApKSn461//ioSEBCxevNhbtRJ5nFIuQ7w+CPH6oKvuV2Oy4myVCWerTThbZUK5sR5nq00oN17cdupcLapNVvxy2ohfThudx2o1CtzULQo394jGzT2i0SHs6u9FRETXp8XDUvHx8fjyyy8xZMgQAMCCBQuwdetWbN++HQDwySefYNGiRcjLy/NetR7AYSnyFrvdsUBhXokBeWeMyCsxIufUBVy47Kai3WJCcXP3aHSMCIIuSAmdRgl9sOOrLkgBfZASQUq5y8rfRETtnVeGpS5cuIDY2Fjnz1u3bsWYMWOcP99www0oKipqRblEgUEmE9AxMhgdI4Mxpm88AMel6wdPG7D1yFlkHzuL3MILON6wIvPVBKvk6BGrRe8EHVLidUiJ0yIiRIVglQJBKjmCVXLO7SEiuoIWh5vY2FgUFBQgKSkJZrMZ+/btw5IlS5zPV1VVQankeiJEl5LLBAxMCsPApDDM/k13GGot2H68ArtPnMP5GjOM9RYY6yww1lthqHN8b7WLqDXbsL+oEvuLKq/42iq5zBl0Gr8GqxQIVsmh1SihD1I09AY19A4FOXqGGrfpg5TQahQMSUQUcFocbsaMGYPnnnsOr7zyCj7//HMEBwdj5MiRzucPHDiArl27eqVIokChD1ZiXP94jOsf3+zzoiiizmLDmcp65Jc4hrbyS4w4VlYNY70FtWYbbA13Vzfb7DDX2WGoszT7Wi0VpJRDq1FA1xB2dBrH17BgJeJ0moY5SRrEhzm+cuVnIvJ1LQ43L774IqZMmYJRo0YhNDQU77//PlQqlfP5zMxMpKene6VIovZCEAQEqxToFhOKbjGhmDAgweV5URRhttlRZ7ah1mxDrdna8NWGOrMNNWYrak02VJku9gQ5e4fqrM7vDXUW1DSs7FxncdzDq7zK1FxJTXQIC0JKvBa94nToFa9FrzgtOkeG8IowIvIZrboreGhoKORy1/97O3/+PEJDQ10Cjy/ihGIiB4vNjup6K6rqG0JPvQVVjT/XWVBZa0aJob7hUYcSQ32zt7oALl4C3ytOh56xWkRr1dAHKxEerEJYkBJhwUpoNUrIuRI0EbWSVyYUN9Lr9c1uj4iIcPeliEhCSrkM4SEqhIe07H9IRFFEZa0FR8uqcKSsCvklVThcasSR0irUmm1NLoG/nCAA+iAlwoKU0DeEnvBgJeLDgtC/gx79EvXoEBbEq8SI6LpxPXkiahFBEBAeosLQLpEY2iXSud1uF1F0odYZdo6XV+NCrRmVtZaGhxk1ZhtEEc5tuMJCiJEhKvRL1KN/Yhj6d9Cjf5IeMVr/uLULEfkO3n6BiLzObHVMfK6sNaOyzhFwHAHIjIKKWhworsSR0ipY7U3/cxSv16BfBz0GJIWhd7wOkaEq5xVfvNqLqP3w6rAUEZG7VAqZ855cV1JvsSG/xIiDpw34uciAg6crcay82jnvZ3NeWbPHBavkjsvcNa6XuusargC7dHHESy+N1wUpOA+IKEAx3BCRT9Ao5RjUMRyDOoYDwx3bakxWHDpjxIHiShwoNuBoWVWTq70arxYrMdS36n1D1QroNArH/KNgxxykyBAVEsIcl8EnhGkQpw9CrFbNK8KI/ATDDRH5rBC1AjcmR+DG5KYXLFht9otXejVc5u56+bvrpe/GhqvAGp+rszjCUbXJimqTFWeuEY5kAhCj1SA+TIOEhrV/4vQahKoVCFYrENKwmGKISoEQtRxBKse2YJUCKgVDEVFbYrghIr+kcPNqr8uZrXaX8NM4D+h8jRkV1WbH5e+V9ThjqEOZsR4Wm4hSYz1KjfXIRaV7tcoEBKvkCA9RISk8GInhQUiKuPg1KTwYUaEqXilG5CEMN0TULqkUMkSFqhEVeuV5QI3sdhEV1SacMdSjpLLOufZPmdGEGpO1yYKKNQ3fm612AIDVLjp6juqtOHWFK8U0ShkSw4OR1BB4kqNC0D1Gix6xoYjWqhl8iNzAcENEdA0ymYAYnQYxOg0GJoW1+DirzY5aiw21JkfgqagyoehCHYrO16L4Qh2KLtSi+HwtSoz1qLfYr3hTVX2QEl2jQxAWrEJww9BXsNr1a9Dl21VyhDQMlwWrFQhWyiHj5GlqJxhuiIi8RCGXQSeXQadx3FS4a3Qohjazn9lqx5lKR9gpOu/4+mtD0Dl5rgaGOgv2FVZedz1BSjlC1BdvsBqqViBGp0aMVoNYnQaxOrXL11C1gj1G5JcYboiIJKZSyNA5KgSdo0KaPFdvsaGgogYFFTWorrc6h7wah8NqTNaG3iErahqHx0wX7zNWY7aicfmgxvuIAeYW1RWskiNWp0GM1jX0RIWqoVHKoFLIoFbIoVLIoJI7fm78Xq1w/ZlXmlFbYrghIvJhGqUcKfE6pMS3btFRURRhstovhiGzFTUmRwgy1llxtqoeZVUmlBnrGx6O76vqHfs3BqvrJZcJ1wxAauWlIUnu/L5xP7VCdnH4rWHY7dKvwSoOw5EDww0RUQATBAEapRwapRyR197dqdZsRXlD0CmrMqHcWI9Sg+P7c9UmmKx2mBsfNjtMFpvj6yXbLl3/3mYXUWe3OS/BbwuXD8NdDEGXz09SOPdzfm28tL/hGK3asfAjh+n8A8MNERE1EaxSoHOUotmhspYQRRFWu+gSgMxWR/gxWW1NtjtDUpPQZIfZZnMeW3fpFWkmW5NhutrrGIa79r+JHB0jgpEUEYyODY+kiCB0jAhGYngwNEq5R96Hrh/DDREReZwgCFDKBSjlMoRc+2p7j7naMJzzq9kxR6kxDDX+3Dhnqbn9zVY7as02HC6twuHSqmbfO1andgSe8EsCUKTja3SomsNkbYjhhoiIAkZrh+Gupd5iw+nKOhSed1y+X+h8OC7trzZZG+YrmbDn5IUmx6sUMnSODEZKvA6943XonaBruBFsGya/doR3BSciIroOoiiistZySeCpRdH5WhRdcHx/prIetmbueA8AcTqNM+j0SXCEnqTwYPbyNMOdz2+GGyIiIi+y2OwoqazHr2erkVdiRN4ZI/JKjFe8Ci1UrcBDNyVj7u092rhS3+bO5zeHpYiIiLxIKZc55t5EBuPWXjHO7dUmK46UGnHozMXAc7i0CtUmK9747hhuTI7AiG5RElbuv9hzQ0RE5COsNjsWbTyEdT8WoltMKP5v9kgouQAiAPc+v/kvRkRE5CMUchn+545eiAxR4Xh5Nd7feVLqkvwSww0REZEP0Qcr8eyYXgCAFd8eQ7mxXuKK/A/DDRERkY+5OzURA5LCUG2yYtn/HZa6HL/DcENERORjZDIBSyf2gSAAn+Wexk8F56Uuya8w3BAREfmgAUlhuO+GJADAwi9+gdVml7gi/8FwQ0RE5KOeuaMX9EFKHC6twoc/FUpdjt9guCEiIvJRESEqPH1HTwDAa98cwblqk8QV+QeGGyIiIh/2wI0d0TteB2O9Fa9+fUTqcvwCww0REZEPk8sELJ3UBwCwfm8R9hdVSluQH2C4ISIi8nFDOkdgyuAOAByTi+1XuBEnOUgeblatWoXk5GRoNBqkpqZi27ZtV9x3w4YNuP322xEdHQ2dTofhw4fjm2++acNqiYiIpPHc2F7QqhU4UGzAv/cWSV2OT5M03Kxfvx5z5szBggULkJubi5EjR2Ls2LEoLGx+Rnh2djZuv/12bNq0CTk5Obj11lsxYcIE5ObmtnHlREREbStGq8GchjuFv/L1YVTWmiWuyHdJeuPMoUOHYvDgwVi9erVzW0pKCiZPnoxly5a16DX69OmDqVOnYuHChc0+bzKZYDJdnF1uNBqRlJTEG2cSEZHfsdjsGPfmNhwtq8b04Z2wdFJfqUtqM35x40yz2YycnBykp6e7bE9PT8fOnTtb9Bp2ux1VVVWIiIi44j7Lli2DXq93PpKSkq6rbiIiIqko5TIsnuiYXPyv3adw6IxB4op8k2ThpqKiAjabDbGxsS7bY2NjUVpa2qLX+Nvf/oaamhrce++9V9xn/vz5MBgMzkdREccpiYjIf6V1jcL4/vGwi8DCLw5BwgEYnyX5hGJBEFx+FkWxybbmfPTRR1i8eDHWr1+PmJiYK+6nVquh0+lcHkRERP5swbgUBKvkyDl1AZ/lnpa6HJ8jWbiJioqCXC5v0ktTXl7epDfncuvXr8dDDz2Ef//73/jNb37jzTKJiIh8Trw+CE+O7g4A+Mumw6iqt0hckW+RLNyoVCqkpqYiKyvLZXtWVhbS0tKueNxHH32EBx98EB9++CHGjRvn7TKJiIh80sybOqNLVAgqqk1449tjUpfjUyQdlpo3bx7WrFmDzMxM5OfnY+7cuSgsLERGRgYAx3yZ6dOnO/f/6KOPMH36dPztb3/DsGHDUFpaitLSUhgMnFBFRETti1ohx6KGycXv7TyJo2VVElfkOyQNN1OnTsWKFSuwdOlSDBw4ENnZ2di0aRM6deoEACgpKXFZ8+bdd9+F1WrF448/jvj4eOdj9uzZUjWBiIhIMqN6RCO9dyxsdhGLOLnYSdJ1bqTgznXyREREvq7ofC1+s3wrTFY7Vj4wCOP7J0hdklf4xTo3REREdP2SIoLx2C3dAAAvfZWPGpNV4oqkx3BDRETk5/40qguSIoJQYqjH21uOS12O5BhuiIiI/JxGKcfC8Y7Jxf/YdgInzlZLXJG0GG6IiIgCwG9SYnBLz2hYbCIWf5nXricXM9wQEREFAEEQsGhCH6jkMmQfPYusvDKpS5IMww0REVGASI4KwSM3JwMAlv43D/UWm8QVSYPhhoiIKIA8fms3xOs1KL5Qh3e2/ip1OZJguCEiIgogwSoF/t+43gCA1T/8iqLztRJX1PYYboiIiALMnf3ikNY1EiarHUv/myd1OW2O4YaIiCjACIKAJRP7QCETkJVXhi1HyqUuqU0x3BAREQWg7rFaPJjWGQCw9Ms8mKztZ3Ixww0REVGAmv2b7ojWqlFQUYO12wukLqfNMNwQEREFKK1Giefv7AUAeOu74ygx1ElcUdtguCEiIgpgkwd2wA2dw1FnseHFr/KlLqdNMNwQEREFMEEQsHhiH8gE4KsDJdh5vELqkryO4YaIiCjA9UnQ43fDOgEAFm08BIvNLnFF3sVwQ0RE1A48dXtPRISocKy8Gu/vPCl1OV7FcENERNQO6IOVeHZMTwDAim+PobyqXuKKvIfhhoiIqJ24JzUJAxL1qDZZ8fKmw1KX4zUMN0RERO2ETCZg6aS+EARgQ+5p7Dl5XuqSvILhhoiIqB0ZkBSGqUOSAAALvzgEm12UuCLPY7ghIiJqZ/5nTC/og5TILzHiwx9PSV2OxzHcEBERtTMRISo8nd4DAPDXb47gXLVJ4oo8i+GGiIioHXpgaCf0jtfBWG/FX785InU5HsVwQ0RE1A7JZQKWTuoDAFi/twj7iyqlLciDGG6IiIjaqSGdIzBlUAeIIrDoi19gD5DJxQw3RERE7dhzd/ZCqFqBn4sN+CSnSOpyPILhhoiIqB2L0Wow5zfdAQCvfH0EhlqLxBVdP4YbIiKidm5GWmd0jwnF+Roz/pbl/5OLGW6IiIjaOaVchiUTHZOL/7X7FA6dMUhc0fVhuCEiIiKkdYvCuP7xsIvAoi8OQRT9d3Ixww0REREBAP7fuBQEKeXYe+oCPt9/WupyWo3hhoiIiAAA8fogPHlbNwDAXzYdRlW9f04uZrghIiIip4duSkZyVAjOVpnwxrfHpC6nVRhuiIiIyEmtkGPRhN4AgPd2nsTRsiqJK3Ifww0RERG5uKVnDG7vHQubXcTijf43uZjhhoiIiJpYOL431AoZdv56DpsOlkpdjlsYboiIiKiJpIhgPHpLVwDAi1/lodZslbiilmO4ISIiomZljOqKxPAglBjq8faW41KX02IMN0RERNQsjVKOheMdk4v/kV2AgooaiStqGYYbIiIiuqLbe8diVI9omG12v5lczHBDREREVyQIAhZN6A2lXMDWo2fxbX651CVdE8MNERERXVWX6FA8MrILAGDpfw+h3mKTuKKrY7ghIiKia3pidDfE6zUoOl+Hd7eekLqcq2K4ISIiomsKVimwYFwKAGDVD8dRdL5W4oqujOGGiIiIWmRcv3gM7xIJk9WOP/83T+pyrojhhoiIiFpEEAQsmdQHCpmAzXll+OGIb04uZrghIiKiFusRq8WDaZ0BAEu+zIPJ6nuTixluiIiIyC2zf9MdUaFqFFTUIHP7SanLaYLhhoiIiNyi1Sjx/J29AABvfX8MJYY6iStyxXBDREREbrtrUAcM6RSOWrMNL32VL3U5LhhuiIiIyG2Nk4tlAvDfAyXY+WuF1CU5MdwQERFRq/RJ0ON3wzoBABZvPASLzS5xRQ4MN0RERNRq827vgYgQFY6WVeODXaekLgcAww0RERFdh7BgFf7njp4AgBVZR1FeVS9xRQw3REREdJ3uHZKEAYl6VJmsePn/DktdDsMNERERXR+ZTMCSSX0hCMCGfaex9+R5aeuR9N0BrFq1CsnJydBoNEhNTcW2bduuuv/WrVuRmpoKjUaDLl264J133mmjSomIiOhKBiaFYeqQJADAwi8OwWYXJatF0nCzfv16zJkzBwsWLEBubi5GjhyJsWPHorCwsNn9CwoKcOedd2LkyJHIzc3F888/j1mzZuE///lPG1dOREREl3vmjp7QaRTQahSorDVLVocgiqJk0Wro0KEYPHgwVq9e7dyWkpKCyZMnY9myZU32f/bZZ7Fx40bk519cLCgjIwM///wzdu3a1ex7mEwmmEwm589GoxFJSUkwGAzQ6XQebA0RERGdrKhBp8hgCILg0dc1Go3Q6/Ut+vyWrOfGbDYjJycH6enpLtvT09Oxc+fOZo/ZtWtXk/3vuOMO7N27FxaLpdljli1bBr1e73wkJSV5pgFERETUROeoEI8HG3dJFm4qKipgs9kQGxvrsj02NhalpaXNHlNaWtrs/larFRUVza+MOH/+fBgMBuejqKjIMw0gIiIin6SQuoDL050oildNfM3t39z2Rmq1Gmq1+jqrJCIiIn8hWc9NVFQU5HJ5k16a8vLyJr0zjeLi4prdX6FQIDIy0mu1EhERkf+QLNyoVCqkpqYiKyvLZXtWVhbS0tKaPWb48OFN9t+8eTOGDBkCpVLptVqJiIjIf0h6Kfi8efOwZs0aZGZmIj8/H3PnzkVhYSEyMjIAOObLTJ8+3bl/RkYGTp06hXnz5iE/Px+ZmZlYu3Ytnn76aamaQERERD5G0jk3U6dOxblz57B06VKUlJSgb9++2LRpEzp1ctxhtKSkxGXNm+TkZGzatAlz587F22+/jYSEBLz55pv47W9/K1UTiIiIyMdIus6NFNy5Tp6IiIh8g1+sc0NERETkDQw3REREFFAYboiIiCigMNwQERFRQGG4ISIiooDCcENEREQBRfJ7S7W1xivfjUajxJUQERFRSzV+brdkBZt2F26qqqoAAElJSRJXQkRERO6qqqqCXq+/6j7tbhE/u92OM2fOQKvVXvXu461hNBqRlJSEoqKigFwgMJDbF8htAwK7fYHcNiCw2xfIbQMCu31StE0URVRVVSEhIQEy2dVn1bS7nhuZTIbExESvvodOpwu4X+RLBXL7ArltQGC3L5DbBgR2+wK5bUBgt6+t23atHptGnFBMREREAYXhhoiIiAIKw40HqdVqLFq0CGq1WupSvCKQ2xfIbQMCu32B3DYgsNsXyG0DArt9vt62djehmIiIiAIbe26IiIgooDDcEBERUUBhuCEiIqKAwnBDREREAYXhxkNWrVqF5ORkaDQapKamYtu2bVKXdE3Lli3DDTfcAK1Wi5iYGEyePBlHjhxx2efBBx+EIAguj2HDhrnsYzKZ8OSTTyIqKgohISGYOHEiiouL27IpzVq8eHGT2uPi4pzPi6KIxYsXIyEhAUFBQbjllltw6NAhl9fw1bZ17ty5SdsEQcDjjz8OwP/OW3Z2NiZMmICEhAQIgoDPP//c5XlPnasLFy7g97//PfR6PfR6PX7/+9+jsrLSy627evssFgueffZZ9OvXDyEhIUhISMD06dNx5swZl9e45ZZbmpzT++67T/L2Xevceep30RfPHYBm/w4FQcBf//pX5z6+eu5a8hngr397DDcesH79esyZMwcLFixAbm4uRo4cibFjx6KwsFDq0q5q69atePzxx7F7925kZWXBarUiPT0dNTU1LvuNGTMGJSUlzsemTZtcnp8zZw4+++wzfPzxx9i+fTuqq6sxfvx42Gy2tmxOs/r06eNS+8GDB53Pvfrqq1i+fDlWrlyJPXv2IC4uDrfffrvz/mOA77Ztz549Lu3KysoCANxzzz3OffzpvNXU1GDAgAFYuXJls8976lw98MAD2L9/P77++mt8/fXX2L9/P37/+99L2r7a2lrs27cPL7zwAvbt24cNGzbg6NGjmDhxYpN9H3nkEZdz+u6777o8L0X7rnXuAM/8LvriuQPg0q6SkhJkZmZCEAT89re/ddnPF89dSz4D/PZvT6TrduONN4oZGRku23r16iU+99xzElXUOuXl5SIAcevWrc5tM2bMECdNmnTFYyorK0WlUil+/PHHzm2nT58WZTKZ+PXXX3uz3GtatGiROGDAgGafs9vtYlxcnPjyyy87t9XX14t6vV585513RFH07bZdbvbs2WLXrl1Fu90uiqJ/nzcA4meffeb82VPnKi8vTwQg7t6927nPrl27RADi4cOHvdyqiy5vX3N++uknEYB46tQp57ZRo0aJs2fPvuIxvtC+5trmid9FX2ibKLbs3E2aNEkcPXq0yzZ/OHei2PQzwJ//9thzc53MZjNycnKQnp7usj09PR07d+6UqKrWMRgMAICIiAiX7T/88ANiYmLQo0cPPPLIIygvL3c+l5OTA4vF4tL+hIQE9O3b1yfaf+zYMSQkJCA5ORn33XcfTpw4AQAoKChAaWmpS91qtRqjRo1y1u3rbWtkNpvxr3/9CzNnznS5Gaw/n7dLeepc7dq1C3q9HkOHDnXuM2zYMOj1ep9rs8FggCAICAsLc9m+bt06REVFoU+fPnj66add/u/Zl9t3vb+Lvty2S5WVleGrr77CQw891OQ5fzh3l38G+PPfXru7caanVVRUwGazITY21mV7bGwsSktLJarKfaIoYt68ebjpppvQt29f5/axY8finnvuQadOnVBQUIAXXngBo0ePRk5ODtRqNUpLS6FSqRAeHu7yer7Q/qFDh+KDDz5Ajx49UFZWhhdffBFpaWk4dOiQs7bmztupU6cAwKfbdqnPP/8clZWVePDBB53b/Pm8Xc5T56q0tBQxMTFNXj8mJsan2lxfX4/nnnsODzzwgMsNCadNm4bk5GTExcXhl19+wfz58/Hzzz87hyR9tX2e+F301bZd7v3334dWq8WUKVNctvvDuWvuM8Cf//YYbjzk0v9jBhy/KJdv82VPPPEEDhw4gO3bt7tsnzp1qvP7vn37YsiQIejUqRO++uqrJn/Al/KF9o8dO9b5fb9+/TB8+HB07doV77//vnNCY2vOmy+07VJr167F2LFjkZCQ4Nzmz+ftSjxxrprb35fabLFYcN9998Fut2PVqlUuzz3yyCPO7/v27Yvu3btjyJAh2LdvHwYPHgzAN9vnqd9FX2zb5TIzMzFt2jRoNBqX7f5w7q70GQD4598eh6WuU1RUFORyeZP0WV5e3iTt+qonn3wSGzduxJYtW5CYmHjVfePj49GpUyccO3YMABAXFwez2YwLFy647OeL7Q8JCUG/fv1w7Ngx51VTVztv/tC2U6dO4dtvv8XDDz981f38+bx56lzFxcWhrKysyeufPXvWJ9pssVhw7733oqCgAFlZWS69Ns0ZPHgwlEqlyzn15fY1as3voj+0bdu2bThy5Mg1/xYB3zt3V/oM8Oe/PYab66RSqZCamursXmyUlZWFtLQ0iapqGVEU8cQTT2DDhg34/vvvkZycfM1jzp07h6KiIsTHxwMAUlNToVQqXdpfUlKCX375xefabzKZkJ+fj/j4eGcX8aV1m81mbN261Vm3P7TtvffeQ0xMDMaNG3fV/fz5vHnqXA0fPhwGgwE//fSTc58ff/wRBoNB8jY3Bptjx47h22+/RWRk5DWPOXToECwWi/Oc+nL7LtWa30V/aNvatWuRmpqKAQMGXHNfXzl31/oM8Ou/Pa9MU25nPv74Y1GpVIpr164V8/LyxDlz5oghISHiyZMnpS7tqh599FFRr9eLP/zwg1hSUuJ81NbWiqIoilVVVeJTTz0l7ty5UywoKBC3bNkiDh8+XOzQoYNoNBqdr5ORkSEmJiaK3377rbhv3z5x9OjR4oABA0Sr1SpV00RRFMWnnnpK/OGHH8QTJ06Iu3fvFsePHy9qtVrneXn55ZdFvV4vbtiwQTx48KB4//33i/Hx8X7RNlEURZvNJnbs2FF89tlnXbb743mrqqoSc3NzxdzcXBGAuHz5cjE3N9d5tZCnztWYMWPE/v37i7t27RJ37dol9uvXTxw/fryk7bNYLOLEiRPFxMREcf/+/S5/iyaTSRRFUTx+/Li4ZMkScc+ePWJBQYH41Vdfib169RIHDRokefuu1jZP/i764rlrZDAYxODgYHH16tVNjvflc3etzwBR9N+/PYYbD3n77bfFTp06iSqVShw8eLDL5dS+CkCzj/fee08URVGsra0V09PTxejoaFGpVIodO3YUZ8yYIRYWFrq8Tl1dnfjEE0+IERERYlBQkDh+/Pgm+0hh6tSpYnx8vKhUKsWEhARxypQp4qFDh5zP2+12cdGiRWJcXJyoVqvFm2++WTx48KDLa/hq20RRFL/55hsRgHjkyBGX7f543rZs2dLs7+KMGTNEUfTcuTp37pw4bdo0UavVilqtVpw2bZp44cIFSdtXUFBwxb/FLVu2iKIoioWFheLNN98sRkREiCqVSuzatas4a9Ys8dy5c5K372pt8+Tvoi+eu0bvvvuuGBQUJFZWVjY53pfP3bU+A0TRf//2hIYGEhEREQUEzrkhIiKigMJwQ0RERAGF4YaIiIgCCsMNERERBRSGGyIiIgooDDdEREQUUBhuiIiIKKAw3BAREVFAYbghIr+yePFiDBw4UOoyiMiHcYViIvIZgiBc9fkZM2Zg5cqVMJlMLbq5JBG1Tww3ROQzSktLnd+vX78eCxcuxJEjR5zbgoKCoNfrpSiNiPwIh6WIyGfExcU5H3q9HoIgNNl2+bDUgw8+iMmTJ+Mvf/kLYmNjERYWhiVLlsBqteKZZ55BREQEEhMTkZmZ6fJep0+fxtSpUxEeHo7IyEhMmjQJJ0+ebNsGE5FXMNwQkd/7/vvvcebMGWRnZ2P58uVYvHgxxo8fj/DwcPz444/IyMhARkYGioqKAAC1tbW49dZbERoaiuzsbGzfvh2hoaEYM2YMzGazxK0houvFcENEfi8iIgJvvvkmevbsiZkzZ6Jnz56ora3F888/j+7du2P+/PlQqVTYsWMHAODjjz+GTCbDmjVr0K9fP6SkpOC9995DYWEhfvjhB2kbQ0TXTSF1AURE16tPnz6QyS7+v1psbCz69u3r/FkulyMyMhLl5eUAgJycHBw/fhxardblderr6/Hrr7+2TdFE5DUMN0Tk95RKpcvPgiA0u81utwMA7HY7UlNTsW7duiavFR0d7b1CiahNMNwQUbszePBgrF+/HjExMdDpdFKXQ0Qexjk3RNTuTJs2DVFRUZg0aRK2bduGgoICbN26FbNnz0ZxcbHU5RHRdWK4IaJ2Jzg4GNnZ2ejYsSOmTJmClJQUzJw5E3V1dezJIQoAXMSPiIiIAgp7boiIiCigMNwQERFRQGG4ISIiooDCcENEREQBheGGiIiIAgrDDREREQUUhhsiIiIKKAw3REREFFAYboiIiCigMNwQERFRQGG4ISIiooDy/wE3lrNUDomK/AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time_grid_train_interp_np, surv_test_interp_np[0])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Survival probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d9dda8-214c-4d57-afb3-60920423fe9e",
   "metadata": {},
   "source": [
    "### Computing test set evaluation metrics\n",
    "\n",
    "Here, we use the interpolated survival functions (along with their corresponding interpolated time grid).\n",
    "\n",
    "As for choosing evaluation times, we still pick these based on the test set's observed times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60cfabe1-2776-4a56-87d2-a0a26c58126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_grid_test_np = np.unique(Y_test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990db693-f3b6-468a-a66f-fefce44a6c11",
   "metadata": {},
   "source": [
    "Since DeepHit does not make the proportional hazards assumption and can predict survival curves without shape constraints, Harrell's concordance index (Harrell et al., 1982) is not a valid evaluation metric to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931e241e-7648-4d28-91c8-ffc5942a13c9",
   "metadata": {},
   "source": [
    "#### Time-dependent concordance index (Antolini et al., 2005) using the PyCox implementation (Kvamme et al., 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e93bae8-67f1-4b2b-ac35-41270d413fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-dependent concordance index: 0.6088737721195845\n"
     ]
    }
   ],
   "source": [
    "from pycox.evaluation import EvalSurv\n",
    "\n",
    "eval_pycox = EvalSurv(surv_test_interp_df, Y_test_np, D_test_np)\n",
    "C_td = eval_pycox.concordance_td('antolini')\n",
    "print(f'Time-dependent concordance index: {C_td}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25beae8-6208-41b0-a7ed-20e0d6f10ad7",
   "metadata": {},
   "source": [
    "#### Truncated time-dependent concordance index (Uno et al., 2011) using the scikit-survival implementation (Plsterl, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2875af8-4377-4d2a-a05d-380b0de2f82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval time 316.0 - truncated time-dependent concordance: 0.5952383597241816\n",
      "Eval time 693.0 - truncated time-dependent concordance: 0.594074585623196\n",
      "Eval time 1291.0 - truncated time-dependent concordance: 0.593412206245962\n"
     ]
    }
   ],
   "source": [
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import concordance_index_ipcw\n",
    "\n",
    "# convert training and test labels into the structured array format used by scikit-survival\n",
    "labels_train_sksurv = Surv.from_arrays(D_train_np, Y_train_np)\n",
    "labels_test_sksurv = Surv.from_arrays(D_test_np, Y_test_np)\n",
    "\n",
    "# as an illustrative example, we evaluate the truncated time-dependent concordance index at\n",
    "# 25, 50, and 75 percentile values of the time grid we specified earlier\n",
    "eval_time_indices = [int(.25 * len(time_grid_test_np)),\n",
    "                     int(.5 * len(time_grid_test_np)),\n",
    "                     int(.75 * len(time_grid_test_np))]\n",
    "\n",
    "for eval_time_index in eval_time_indices:\n",
    "    eval_time = time_grid_test_np[eval_time_index]\n",
    "\n",
    "    # find the interpolated time grid's time point closest to the evaluation time\n",
    "    interp_time_index = np.argmin(np.abs(eval_time - time_grid_train_interp_np))\n",
    "    surv_values_at_eval_time_np = surv_test_interp_np[:, interp_time_index]\n",
    "\n",
    "    estimated_risks_np = 1 - surv_values_at_eval_time_np\n",
    "    concordance = concordance_index_ipcw(labels_train_sksurv, labels_test_sksurv, estimated_risks_np, tau=eval_time)[0]\n",
    "    print(f'Eval time {eval_time} - truncated time-dependent concordance: {concordance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27d2851-845a-4d8a-a36e-faccc829b824",
   "metadata": {},
   "source": [
    "#### Time-dependent AUC (Uno et al., 2007; Hung and Chiang, 2010) using the scikit-survival implementation (Plsterl, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe777d9e-10e2-49d0-8563-5a7b9889d732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval time 316.0 - time-dependent AUC: 0.6608183075900862\n",
      "Eval time 693.0 - time-dependent AUC: 0.6946235312512404\n",
      "Eval time 1291.0 - time-dependent AUC: 0.6953979312826533\n"
     ]
    }
   ],
   "source": [
    "from sksurv.metrics import cumulative_dynamic_auc\n",
    "\n",
    "for eval_time_index in eval_time_indices:\n",
    "    eval_time = time_grid_test_np[eval_time_index]\n",
    "\n",
    "    # find the interpolated time grid's time point closest to the evaluation time\n",
    "    interp_time_index = np.argmin(np.abs(eval_time - time_grid_train_interp_np))\n",
    "    surv_values_at_eval_time_np = surv_test_interp_np[:, interp_time_index]\n",
    "\n",
    "    estimated_risks_np = 1 - surv_values_at_eval_time_np\n",
    "    AUC = cumulative_dynamic_auc(labels_train_sksurv, labels_test_sksurv, estimated_risks_np, times=[eval_time])[0][0]\n",
    "    print(f'Eval time {eval_time} - time-dependent AUC: {AUC}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d2ae6f-d8db-4bd5-93fd-6075bb478dd3",
   "metadata": {},
   "source": [
    "#### Brier score (Graf et al., 1999) using the SurvivalEVAL implementation (Qi et al., 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "594ed417-a759-4871-91fe-657e3d02f111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval time 316.0 - Brier score: 0.23129584902500178\n",
      "Eval time 693.0 - Brier score: 0.2082869725085887\n",
      "Eval time 1291.0 - Brier score: 0.18742686043310824\n",
      "Integrated Brier score: 0.19032579653742368\n"
     ]
    }
   ],
   "source": [
    "from SurvivalEVAL.Evaluator import SurvivalEvaluator\n",
    "\n",
    "eval = SurvivalEvaluator(surv_test_interp_np, time_grid_train_interp_np,\n",
    "                         Y_test_np, D_test_np,\n",
    "                         Y_train_np, D_train_np)  # note: training labels are also needed\n",
    "\n",
    "for eval_time_index in eval_time_indices:\n",
    "    eval_time = float(time_grid_test_np[eval_time_index])\n",
    "    print(f'Eval time {eval_time} - Brier score: {eval.brier_score(eval_time)}')\n",
    "\n",
    "IBS = eval.integrated_brier_score()\n",
    "print(f'Integrated Brier score: {IBS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d898890-64df-4aac-a27c-e0e33132a505",
   "metadata": {},
   "source": [
    "#### D-Calibration (Haider et al., 2020) using the SurvivalEVAL implementation (Qi et al., 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5281245-920b-4f82-941c-66e7d35d34c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is not D-calibrated.\n"
     ]
    }
   ],
   "source": [
    "p_value, bin_stats = eval.d_calibration()\n",
    "if p_value >= .05:\n",
    "    print('The model is D-calibrated.')\n",
    "else:\n",
    "    print('The model is not D-calibrated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2533edb-260c-4e16-9e09-b59954a9196f",
   "metadata": {},
   "source": [
    "#### Mean Absolute Error via the margin (Haider et al., 2020) and, separately, the Pseudo Observation approach (Qi et al., 2023) both using the SurvivalEVAL implementation (Qi et al., 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94aac7b8-2d20-437a-9b5d-304db3971ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted MAE-Margin: 598.4784722301928\n"
     ]
    }
   ],
   "source": [
    "weighted_MAE_margin = eval.mae(method='Margin', weighted=True)\n",
    "print(f'Weighted MAE-Margin: {weighted_MAE_margin}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc0f800a-a847-44f2-ac85-698c9f72a881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted MAE-PO: 716.2569627330386\n"
     ]
    }
   ],
   "source": [
    "weighted_MAE_PO = eval.mae(method='Pseudo_obs', weighted=True)\n",
    "print(f'Weighted MAE-PO: {weighted_MAE_PO}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
